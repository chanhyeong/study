= 4. 카프카 내부 동작 원리와 구현

== Replication

=== 동작 개요

* 토픽 생성 시 `replication-factor` 옵션 설정
* 복제는 토픽이 아닌 파티션 단위로 된다

.파티션 1, 복제 수 3개인 토픽 생성 및 조회
[source,bash]
----
[ ~]$ /kafka-topics.sh --bootstrap-server {server} --create --topic {topic} --partitions 1 --replication-factor 3

Created topic {topic}

[ ~]$ /kafka-topics.sh --bootstrap-server {server} --topic {topic} --describe

Topic: peter-test01 PartitionsCount: 1 ReplicationFactor: 3 Configs: segment.bytes=1073741824
Topic: peter-test-1 Partition: 0 Leader 1 Replicas: 1,2,3 Isr: 1,2,3 // <1>
----
<1> 리더는 1, 리플리케이션은 1,2,3, 동기화 1,2,3 으로 되고 있음

=== Leader, Follwer

* Leader
** 특정 파티션에 대한 producer/consumer 에 대한 모든 읽기와 쓰기 동작을 담당
* Follower
** consumer 의 동작과 비슷하게 지속적으로 리더가 메시지를 새로 받았는지 확인하여 복제

=== 복제 유지와 커밋

* ISR (InSyncReplica): Leader, Follower 가 묶인 논리적 그룹
** Follower: 지속적으로 리더의 데이터를 따라감
** Leader: 모든 Follower 가 메시지를 받을 때까지 기다림 (잘 받는지 계속 감시)
*** 복제를 하지 않는 Follower 는 ISR 에서 추방
* high water mark: 모든 Follower 가 복제 완료 시 Leader 가 내부적으로 커밋됐다고 남기는 표시
** 커밋되었다 = 모든 리플리케이션이 전부 메시지를 저장했다
** 커밋된 메시지만 컨슈머가 읽어갈 수 있음
*** (여기서 커밋이랑 추후에 트랜잭션 커밋이랑은 다른 개념일듯)
*** (커밋이 총 3개, 복제 커밋, 트랜잭션 커밋, 컨슈머 커밋)
** 커밋되지 않은걸 가져가면 리더 재선출 과정에서 불일치가 발생할 수 있음 (120p)

.현재 커밋된 위치 확인하기
[source,bash]
----
[ ~]$ cat /data/kafka-logs/replication-offset-checkpoint

topic01 0 1 // <1>
----
<1> 토픽이 0번 파티션의 커밋된 오프셋 번호는 1

=== Leader, Follower 의 단계별 복제 동작

Leader 의 부하를 줄여주기 위한 설계

. Leader 에 새로운 메시지 인입 (offset 0)
. Follower 가 `fetch` 요청을 보내고 복제 수행
** 이 때 Leader 는 Follower 아 복제 요청을 보낸 것을 알고 있음 (성공/실패는 모름)
. Leader 에 다음 메시지가 인입 (offset 1)
. Follower 가 다음 offset 2에 대해 2번 작업 재수행
. 다음 오프셋에 대한 요청을 받으면 Leader 가 offset 1은 성공으로 인지 -> high water mark 증가
. Leader 가 offset 1 복제 요청을 받으면 응답에 offset 0 메시지가 커밋되었다는 내용도 전달
. Follower 는 Leader 의 응답을 받고 동일하게 커밋 표시

==== 여기서 궁금한점

* 다음 메시지가 넘어오지 않으면 어떻게 되는가 - 뭔가 타임아웃 설정이 있나

=== LeaderEpoch 와 복구

* LeaderEpoch: 파티션들이 복구 동작을 할 때 메시지의 일관성을 유지하기 위한 용도
** 컨트롤러가 관리하는 32bit 숫자
** 복구 동작 시 high water mark 를 대체하는 수단으로도 활용

==== LeaderEpoch 없을 때 흐름 (Leader -> Follower 순으로 죽음)

. Follower 가 다음 high water mark 를 받지 못한 채 죽음
. Follower 가 새로 뜸. Leader mark != Follower mark
** 가지고 있는 오프셋 이후의 데이터를 지움
. 복제되기 전에 Leader 가 죽음
. Follower 가 Leader 로 승격 (메시지 손실)

==== LeaderEpoch 있을 때 흐름 (Leader -> Follower 순으로 죽음)

. Follower 가 다음 high water mark 를 받지 못한 채 죽음
. Follower 가 새로 뜸. LeaderEpoch 요청
** Leader 가 본인의 offset, 메시지 정보를 보냄 -> Follower 에 복제된 데이터 유지
. 복제되기 전에 Leader 가 죽음
. Follower 가 Leader 로 승격 (메시지 손실)

==== LeaderEpoch 없을 때 흐름 (Leader -> Follower 둘 다 죽고 Follower 먼저 복구)

. 둘 다 죽음, Follower 가 먼저 복구되면서 새로운 Leader 로 승격
. Leader 가 복구되었으나 새로운 Leader 와 메시지를 다르게 보관

==== LeaderEpoch 있을 때 흐름 (Leader -> Follower 둘 다 죽고 Follower 먼저 복구)

. 둘 다 죽음, Follower 가 먼저 복구되면서 새로운 Leader 로 승격
. 새로운 Leader 는 본인이 Follower 일 때의 high water mark 도 알고 있음

상세 동작 132 ~ 137p

=== Controller

* 리더 선출 역할 - 카프카 클러스터 중 하나의 브로커
* 파티션 ISR 에서 Leader 선출
** ISR 리스트 정보는 Zookeeper 에 저장되어 있음
* Leader 장애 발생 시나리오
.. 1번 종료
.. Zookeeper 가 연결이 끊어지고 ISR 변화 감지
.. Controller 는 Zookeeper watch 를 통해 감지, ISR 중에서 새로 리더 선출
.. Controller 가 Zookeeper 에 새로운 리더 정보 저장
.. 모든 브로커에 전파
* 현재 1만 개 파티션 기준 3초
* graceful 변경 시나리오
.. 종료 신호 받은 브로커가 Controller 에 알림
.. Controller 가 리더 선출 작업 진행, Zookeeper 에 기록
.. 브로커들에 전송
.. Controller 가 브로커에 정상 종료한다는 응답 보냄
.. 브로커는 캐시에 있는 내용을 디스크로 저장하고 종료
** 기본값으로 활성화되어 있음 `controlled.shutdown.enable`

=== Segment

* Message key, value, offset, size 가 같이 저장
* 최대 크기는 디폴트 1GB. 롤링
* 관리 계획 - 삭제, 압축

==== 삭제

* 디폴트로 활성화되어 있음 `log.cleanup.policy=delete`
* 토픽별 `retention.ms` 에 따라 정해짐
* 기본 5분 주기로 파일 체크하면서 삭제 수행
* 파일 네이밍 룰
** 파일명의 끝은 오프셋 번호 (ex. 0000000002.log)

==== Compaction

* 활성화된 세그먼트는 제외한 나머지를 대상으로 실행
* 메시지의 키 값을 기준으로 마지막 데이터만 보관
** 과거 정보는 중요하지 않고 가장 마지막 값이 필요한 경우
* 기능을 사용하려면 키를 필수로 전송해야 함
* 빠른 장애 복구가 장점 - 키를 기준으로 최신의 상태만 복구
* 키 값을 기준으로 최종값만 필요한 데에서만 적용하는 것이 좋음
* 브로커 I/O 부하가 발생 할 수 잇음 - 모니터링 병행 필요

상세 옵션: 148p
