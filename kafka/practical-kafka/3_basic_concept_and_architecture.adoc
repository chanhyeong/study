= 3. 카프카의 기본 개념과 구조

== 기초

=== Replication

메시지를 여러 개로 복제하여 카프카 클러스터에 분산 `replication-factor`

* replication factor 가 크면 안정성 높음, 리소스 사용
* 오버헤드를 줄여서 사용
** 개발: 1
** 운영: 2 (로그성, 유실 허용) or 3 (유실 허용하지 않음)
*** 3대 기준이고 실제 브로커 대수에 따라 다를 수 있음

=== Partition

하나의 토픽이 처리할 수 있는 한계를 높이기 위해 병렬 처리가 가능하게 나눈 것

* 생성 수? (한 번 늘리면 줄일 수 없다)
** 작게 생성 한 후, 처리량이나 lag 등을 모니터링하며 늘려가기

=== Segment

메시지가 로그 파일 형태로 브로커의 로컬 디스크에 저장되는 형태

== 핵심 개념

=== 분산 시스템

확장 가능

=== Page Cache

직접 Disk I/O 대신 OS 단에서 제공하는 잔여 Memory 이용

=== 배치 전송 처리

단 건 대신 모아서 전송 처리

=== 압축 전송

gzip, snappy, lz4, zstd, ...

* 네트워크 대역폭, 회선 비용 감소
* 높은 압축 - gzip, zstd
* 빠른 속도 - lz4, snappy

=== topic, partition, offset

* offset 을 이용하여 메시지의 순서를 보장, consumer 의 마지막 읽은 위치 파악

=== 고가용성 보장

Replication 내용과 동일

* leader, follower

=== Zookeeper 의존성

* 분산 애플리케이션 코디네이터
* znode 를 이용해 메타 정보 기록
** 노드, 토픽, 컨트롤러 관리 등

== Producer 기본 동작 및 예제

=== Producer design

* ProducerRecord: 전송할 데이터
** topic, partition, key, value 로 구성
* partition 지정 시?
** 아무 동작을 하지 않고 레코드 전달
* partition 미지정 시?
** key 를 가지고 파티션 선택 - 기본은 round robin
* 레코드를 파티션 별로 잠시 모아둠 - 배치 전송

=== 주요 옵션

.주요 프로듀서 옵션
[cols="2,4"]
|===
|옵션 |설명

|bootstrap.servers
|처음 연결하기 위한 host:port 정보

|client.dns.lookup
|하나의 IP 와 연결하지 못할 경우 다른 IP 로 시도 설정 +
디폴트 use_all_dns_ips

|acks
|리더 측에 메시지 전송 후 요청을 완료하는 기준 +
0 (빠름), 1 (리더가 받았는지 확인), all (leader, follower 전부 받았는지 확인)

|buffer.memory
|설정한만큼 차면 보냄

|compression.type
|압축 타입

|enable.idempotence
|중복 없는 전송, `max.in.flight.requests.per.connection` 5 이하, `retries` 0 이상, `acks` all

|max.in.flights.requests.per.connection
|하나의 커넥션에서 ack 없이 전송할 수 있는 요청 수. 순서가 중요하면 1 설정

|retries
|오류 시 재시도 횟수

|batch.size
|동일 파티션에 배치로 몇 개 보낼 것인지

|linger.ms
|설정한만큼 대기하면 보냄

|transactional.id
|exactly once 전송을 위한 옵션, TransactionalId 에 한해 exactly once 보장

|===

== Consumer 기본 동작 및 예제

=== 기본 동작

* 컨슈머 그룹: 하나 이상의 컨슈머들이 모여있는 그룹, 컨슈머는 반드시 속함
* 각 파티션의 리더에게 토픽에 저장된 메시지를 가져오기 위한 요청을 보냄
* partition:consumer = 1:1 이 이상적

=== 주요 옵션

.컨슈머 주요 옵션
[cols="2,4"]
|===
|옵션 |설명

|bootstrap.servers
|처음 연결하기 위한 host:port 정보

|fetch.min.bytes
|한 번에 가져올 수 있는 최소 데이터 크기 +
작으면 안가져오고 기다림

|group.id
|컨슈머 그룹을 식별하는 식별자

|heartbeat.interval.ms
|컨슈머가 active 한지 체크. session.timeout.ms 의 1/3 값을 설정

|max.partition.fetch.bytes
|파티션 당 가져올 수 있는 최대 크기

|enable.auto.commit
|주기적으로 오프셋 커밋

|auto.offset.rest
|초기 오프셋이 없거나 현재 오프셋이 존재하지 않는 경우 리셋 설정 +
earliest, latest, none (값을 못찾으면 에러)

|fetch.max.bytes
|가져올 수 있는 최대 크기

|group.instance.id
|컨슈머의 고유 식별자, 설정한 경우 static 멤버여서 불필요한 리밸런싱을 하지 않음

|isolation.level
|transaction consumer 에서 사용 + 
read_uncommitted 는 모든 메시지, read_committed 는 transaction 이 완료된 메시지

|max.poll.records
|한 번의 poll() 에서 가져오는 메시지 수

|partition.assignment.strategy
|파티션 할당 전략, 기본은 range

|fetch.max.wait.ms
|요청에 대한 응답을 기다리는 최대 시간

|===

컨슈머 역시 한 번 구동하고 나면 자주 변경되거나 종료되는 현상이 없으므로 auto commit 을 사용하는 경우가 많습니다 +
-> 안씀. 컨슈머는 언제든지 죽을 수 있다는 가정