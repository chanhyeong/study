= 15. 구글 드라이브 설계

== 문제 이해 및 설계 범위 확정

* 파일 업로드/다운로드, 동기화, 암호화, 10GB 제한, 갱신 이력 조회, 공유 알림
* 모바일 앱 웹
* DAU 천만
* 안정성, 빠른 동기화 속도, 네트워크 대역폭

=== 개략적 추정치

* 전체 5천만으로 가정
* 모든 사용자에 10GB 무료 저장공간 할당
* 매일 사용자가 2개 업로드 가정, 각 파일 당 500KB
* read : write = 1 : 1
* 5천만 x 10GB = 500PB
* 업로드 API QPS = 천만 x 2회 업로드 / 24시간 / 3600 초 = 240
* 최대 QPS = QPS x 2 = 280

== 개략적 설계안 제시 및 동의 구하기

=== API

==== 파일 업로드 API

* 단순 업로드
* resumable upload: 업로드가 중단될 가능성이 높다고 생각될 때
** url 을 받기 위한 최초 요청
** 데이터를 업로드하고 업로드 상태 모니터링
** 업로드에 장애가 발생하면, 장애 발생 시점부터 재시작

==== 파일 다운로드 API

==== 파일 갱신 히스토리 API

=== 서버 다중화

* 간단한 방법: user_id 별 샤딩
* Amazon S3 (Simple Storage Service): 규모 확장성, 가용성, 보안, 성능을 제공하는 객체 저장소 서비스
** 같은 지역에서 다중화, 여러 지역에 걸쳐 다중화
** 데이터 무손실을 보장하기 위해 두 개 이상의 지역에 데이터 다중화
* load balancer, metadata db

=== 동기화 충돌

동시에 같은 파일을 갱신하려 하는 경우

. 두 파일을 하나로 합치거나
. 둘 중 하나를 다른 파일로 대체

=== 개략적 설계안 (287p)

* 단말, block server, cloud storage, cold storage, load balancer, api server, metadata db, metadata cache, notification service, offline backup queue

== 상세 설계

=== block server

전체 파일을 서버로 보낼 경우 대역폭을 많이 잡음. 해결볍 2가지

* delta sync: 파일이 수정 되면 수정된 블록만 동기화
* compression: 블록 단위로 압축

. 클라이언트가 보낸 파일을 블록 단위로 나눔
. 블록에 압축 알고리즘 적용, 암호화
** 수정된 블록만 전송해야 함
. cloud storage 로 보냄

이게 네트워크 대역폭을 줄이기 위해서 사용하는건데, 이러면 클라이언트의 대역폭 사용과는 관계가 없지 않나?

=== 높은 일관성 요구사항

같은 파일이 단말이나 사용자에 따라 다르게 보이는 것은 허용할 수 없다

* 메모리 캐시는 eventual consistency
** 캐시 내용과 디비 원본이 일치
** db 변경 발생 시 캐시 무효화
* RDB 는 ACID 를 지원하므로 보장하기 쉬움
* NoSQL 은 동기화 로직을 구현해야 함

=== metadata db

* 사용자 정보, 단말 정보, 사용자별 루트 디렉토리, 파일 정보, 파일 갱신 이력 정보, 파일 블록 보관 정보

=== 업로드 절차 (293p)

. 파일 메타데이터 추가
. 파일을 cloud storage 에 업로드

=== 다운로드 절차

파일이 추가/변경됨을 인지하고 새로 가져가야 하는 것은 어떻게 하는가

294~295p

=== 알림 서비스

파일의 일관성을 유지하기 위해 다른 클라이언트에 알림

* long polling (이거로 선택)
** 채팅과 달리 양방향 통신이 필요하진 않음
* WebSocket

=== 저장소 공간 절약

* 중복 제거 (de-dupe): 파일의 해시 값을 비교
* 지능적 백업 전략 도입
** 한도 설정: 파일 버전 개수의 상한
** 중요한 버전만 보관
* 자주 쓰이지 않는건 cold storage 로 옮김

=== 장애 처리

* LB 장애: secondary LB 를 두고 이어서 받도로 ㄱ함
* block server 장애: 다른 서버에서 처리
* cloud storage 장애: 다른 지역에서 가져옴
* ...
