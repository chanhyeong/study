= 11. 백엔드 컴파일과 최적화

백엔드 컴파일: .class -> 개별 로컬에 맞는 네이티브 코드로 변환

== JIT 컴파일러

* 자바 프로그램 -> 인터프리터로 해석해 실행
* 자주 실행되는 메소드 or 코드 블록 -> 네이티브 코드로 컴파일, 최적화하여 실행 효율을 높임
** hotspot code or hot code
** 백엔드 컴파일러: JIT 컴파일러

=== 인터프리터와 컴파일러

* 인터프리터: 프로그램을 빠르게 시작해야 할 때 컴파일 없이 바로 실행
** 메모리가 부족한 경우 인터프리터 방식으로 메모리 절약
** 적극적 최적화의 가정이 무너지는 경우, 최적화를 취소하고 다시 인터프리터로 맡김
* 컴파일러: 시작된 후 시간이 흐를 수록 네이티브 코드로 컴파일하여 실행 효율을 높임
** 2개 or 3개 내장
** C1 (클라이언트), C2 (서버), Graal
* 계층형 컴파일 모드 전에는 C1, C2 중 하나의 컴파일러와 협력하여 동작
** 클라이언트 모드 or 서버 모드 only
* 혼합 모드: 자바 버전과 머신 하드웨어에 맞추어 자동으로 선택
** -Xint, -Xcomp 설정으로 고정 가능

네이티브로의 컴파일 시 시간이 많이 걸리고, 최적화 할수록 컴파일도 오래 걸림 +
인터프리터가 성능 모니터링 정보를 수집할 수 있으며 이것도 해석과 실행 단계 속도에 영향

==== 계층형 컴파일 기능

* 계층 0: 인터프리터가 순수 해석 실행
* 계층 1: C1 컴파일러. 바이트코드 -> 네이티브 코드 컴파일 실행
** 간단하고 안정적인 최적화
* 계층 2: C1 컴파일러. 몇 가지 성능 모니터링만 수행
* 계층 3: C1 컴파일러. 모든 성능 모니터링 정보 수집
* 계층 4: C2 컴파일러. 성능 모니터링 정보를 활용하여 더 오래 걸리는 최적화까지 수행
** 신뢰도가 낮은 공격적인 최적화를 수행하기도

**인터프리터, C1, C2 컴파일러가 협력해 동작하면서 hot code 가 여러 번 컴파일될 수 있다**

* C1: 빠르게 컴파일
* C2: 성능을 더 높여야 할 때
** 복잡한 최적화 알고리즘을 수행해야 할 때는 C1 으로 간단하게 최적화해두고, 최적화를 천천히 수행도 가능

=== 컴파일 대상과 촉발 조건

.조건
****
. 여러 번 호출되는 메소드
. 여러 번 실행되는 순환문의 본문
****

* 컴파일 대상 = 메소드 전체
* 온스택 치환: 메소드의 스택 프레임이 스택에 존재하는 상태에서 메소드가 치환

==== 코드 블록이 실행되는 횟수 계산? - 핫스팟 코드 탐지

* 샘플 기반: 각 스레드의 호출 스택 상단을 샘플링
** 특정 메소드 or 일부가 자주 발견되면 hot method 로 간주
** 구현은 쉽지만 정확하게 알기는 어렵고 탐지 방해 요소가 있음
* 카운터 기반: 각 메소드와 코드 블록에 대한 카운터 설정
** 실행 횟수가 특정값을 초과하면 hot method 로 간주
** 구현이 번거롭지만 정확하고 엄격한 결과를 얻을 수 있음

==== 메소드 호출 카운터에 의한 JIT 컴파일 촉발

p524, 그림 11-3

* client 모드에서 1500회, server 모드에서 10000회
. 메소드 호출 시 JIT 컴파일 버전이 이미 있는지 확인
. 없으면 호출 카운트 1 증가
** 단위 시간 (counter half life time) 당 호출 횟수
** counter decay method invocation: 단위 시간 동안 도달하지 못하면 카운터의 값을 절반으로 줄임
. 메소드 호출 카운터 + 백 에지 카운터 > 기준값 -> JIT 컴파일 요청
. 컴파일이 완료될 때까지는 인터프리터로 실행
. 컴파일이 완료되면 메소드 호출 진입점 주소가 자동으로 덮어씌워짐. 이후 호출에선 컴파일 버전 사용

==== 백 에지 카운터에 의한 JIT 컴파일 촉발

* 백 에지 카운터: 특정 순환문의 본문 코드가 실행되는 횟수
* client 모드: 메소드 호출 카운터 문턱값 (-XX:CompileThreshold) * OSR 비율 (-XX:OnStackReplacePercentage) / 100 == 기본값 13995
* server 모드: 메소드 호출 카운터 문턱값 * OSR 비율 - 인터프리터 모니터링 비율 / 100 == 기본값 10700
. 백 에지 명령어 발견 시 컴파일된 버전 확인
. 이후 동작은 동일
* 백 에지 카운터는 감쇠가 없고 절대 실행 횟수를 계산

=== 컴파일 과정

* 백그라운드에서 별도 스레드가 수행. 컴파일 완료 전까지는 인터프리터가 프로그램 실행

==== client 컴파일러의 컴파일 과정

p528, 그림 11-5

3단계, 지역 최적화에 집중

. 플랫폼 독립적 프론트엔드 - bytecode -> 타깃 중립적 중간 표현인 HIR 생성
** 코드 값을 정적 단일 할당 (SSA) 로 표현 -> 최적화를 쉽게 구현할 수 있도록 도와줌
** 메소드 인라인, 상수 전파 등 기본 최적화 수행
. 플랫폼 의존적 백엔드 - HIR -> LIR 생성
** LIR: Low Intermediate Representation
** HIR 대상으로 null 검사 제거, 범위 검사 제거 등의 최적화 수행
. 플랫폼 의존적 백엔드 - 선형 스캔 레지스터 할당 (linear scan register allocation)
** LIR 에 레지스터 할당, 핍홀 최적화 수행 -> 네이티브 코드 생성

==== server 컴파일러의 컴파일 과정

서버 측 성능을 극대화하도록 설정된 컴파일러. GNU C++ 컴파일러 수준

* 전통적인 최적화: dead code 제거, 순환문 언롤링, 순환문 표현식 호이스팅, 공통 하위 표현 제거, 상수 전파, 기본 블록 재정렬
* 자바 특화 최적화: 범위 검사, null 검사 제거 등
* 인터프리터 or client 컴파일러에서 제공한 성능 모니터링 정보를 토대로 guided inline, 분기 예측 등 예측 최적화 수행
* 전역 그래프 셰이더 할당기 사용 - 커다란 레지스터 집합의 이점 활용
* 생성한 네이티브 코드의 성능이 client 컴파일러의 것보다 훨씬 좋음
** JDK9 부터 기본 모드

=== 실전: JIT 컴파일 결과 확인 및 분석

일련번호 | 컴파일 아이디 (OSR, 일반) | 컴파일 계층 | 컴파일된 메소드 | (OSR BCI (bytecode index)) | 컴파일된 코드 크기

* 코드 인라인 수행 - 디스패치 부하가 없어진다
** (private method 분리해도 괜찮다)

== AOT 컴파일러

=== AOT 컴파일의 장점과 단점

==== AOT 의 매력

크게 2가지

. 프로그램이 실행되기 전에 프로그램 코드를 네이티브 코드로 컴파일
** 실행되기 전에 컴파일을 정적으로 수행 -> 최적화를 부담없이 수행
** ART 는 앱을 처음 설치할 때 네이티브 코드를 만들어 둔다 -> 설치 시간 소요
. JIT 컴파일러가 런타임에 수행해야 하는 작업을 미리 수행해 캐시해두고 사용
** 동적 AOT or JIT 캐싱
** JIT 컴파일러의 캐시 역할을 극대화하여 구동 시간 단축, 구동 후 빠르게 최상의 성능

최신 JIT 컴파일러는 계층형 컴파일을 수행하여 먼저 빠르게, 그리고 고품질로 최적화

* 제약: JIT 컴파일에 소비된 자원은 결국은 애플리케이션 실행에 사용할 수 있었던 자원
** 컴파일 과정에서 가장 오래 걸리는 최적화 - 프로시저 간 분석 (전체 프로그램 분석)
** 특정 변수가 상수여야 하는가? 코드 블록이 전혀 사용되지 않는가? 가상 메소드 버전이 하나 뿐인가?
** 전체 프로그램을 대상으로 시간이 매우 오래 걸리는 계산 수행

jaotc: 컴파일된 결과를 바로 로드하여 구동 속도를 높이고, 최고 성능으로 실행되는 데 시간까지 단축

==== JIT 의 반격

* 성능 모니터링 기반 최적화
** 정적 분석 단계에서는 얻을 수 없거나, 경험에 의한 추측만 가능한 정보들
* 급진적 예측 최적화
** 정적 최적화에서는 실행 결과 및 겉보기 효과까지 최적화 전후가 완벽히 같아야 함
** JIT 컴파일러는 보수적일 필요가 없다 - 성능 모니터링 정보를 토대로 정확한 판단 확률이 높음
** VM 대부분은 virtual method 가 원활하게 인라인될 수 있도록 일련의 급진적 예측 최적화를 수행
* 링크타임 최적화
** 링크 - 클래스가 런타임에 VM 메모리에 로드 -> JIT 컴파일러가 최적화

=== 실전: jaotc 의 AOT 컴파일

프로그램 구동과 예열 시간을 줄여 최대 성능을 빨리 끌어냄 +
JDK17 부터는 없어짐

== 컴파일러 최적화 기법

핫스팟 VM JIT 컴파일러가 사용하는 몇 가지 최적화 기법. p550 표

* 메소드 인라인, 중복 저장 제거, 복사 전파, dead code 제거
* 바이트코드와 기계어 명령어가 달라지고 실행 효율 측면에서의 차이도 커진다

=== 메소드 인라인

메소드 호출 비용을 없애준다 +
호출 비용을 없애기 위해 대상 메소드의 코드를 호출 메소드로 복사

* 컴파일타임에 해석되는 메소드는 4가지 - private, instance creator, superclass method, static
** 이 외의 메소드는 런타임에 메소드 수신자를 선택해야 한다
* virtual method 는 컴파일타임에 어떤 메소드 버전을 사용할지 결정이 어렵다
** 런타임에 실제 타입을 확인하여 동적 디스패치 필요
* virtual method 인라인을 위해 JVM 은 클래스 계층 구조 분석 기술 도입
** 애플리케이션 전반의 타입 분석 - 현재 로딩된 클래스들이 인터페이스를 구현했는지, subclass 가 있는지, parent 의 virtual method 를 오버라이드 했는지
** guided inline: '후보가 1개 뿐이라면 애플리케이션이 지금 모습에서 변하지 않을 것이다' 라고 가정하고 인라인
*** 언제 새로운 타입이 로드될지 모르기 때문에 급진적 최적화에 속함
* 급진적 최적화가 실패할 경우를 위한 '느린 경로'
** 새로운 클래스가 로드되면 컴파일된 코드를 삭제하거나, 해석 모드로 돌리거나, 다시 컴파일
* 대상 메소드의 후보가 여러 개라면? - 인라인 캐시를 찾는다
** 메소드를 실제로 호출하지만, virtual method table 을 보는 것보단 빠르다
** 대상 메소드에 정상적으로 진입하기 전 확인하는 캐시
*** 메소드가 호출되기 전에는 비어 있음
*** 첫 번째 호출 시 수신자의 버전 정보를 캐시에 기록
*** 후속 호출에서도 매번 버전이 같다면 monomorphic inline cache - 인라인되지 않은 '비가상' 메소드 호출과 비교하여 타입 판단만 거침 == virtual method 호출보단 빠르다
*** 후속 호출에서 달라지만 megamorphic inline cache - virtual method 호출과 동일한 부하

=== 탈출 분석

새로 만들 객체가 사용되는 범위를 분석하여, java heap 에서 메모리를 할당할지 여부 결정

기본 원칙

* 전역 탈출 (GlobalEscape): 객체가 메소드 밖으로 나와 다른 스레드가 접근할 수 있음
* 인수 탈출 (ArgEscape): 객체가 인수로 전달되거나 참조되지만, 호출 중 전역 탈출하지는 않음
* 탈출하지 않음 (NoEscape): 객체가 메소드 내에서 생애를 마침

탈출 수준에 따라 최적화 수준을 달리할 수 있음

* 스택 할당: 객체가 탈출하지 않는게 확실하다면, heap 이 아니라 stack 에 할당
** stack frame 이 사라질 때 객체가 점유하던 메모리도 자동으로 파괴
* 스칼라 치환: 객체라는 껍질을 벗겨 멤버 번수들에 직접 접근할 수 있게 만드는 과정
** 스칼라: 더 작은 표현으로 분해할 수 없는 데이터
** 애초부터 객체를 생성하지 않고, 멤버 변수들을 메소드에서 직접 사용하게 한다
** 객체가 메소드 범위를 벗어나면 안된다
* 동기화 제거: 객체가 탈출하지 않는게 확실하다면, 동기화도 필요없다

객체 탈출 여부를 100% 정확하게 결정하려면, 프로그램의 각 분기가 실행될 때마다 복잡한 프로시저 간 분석을 수행하여 객체에 미치는 영향을 확인해야 한다

JDK 6 업데이트 23 부터 서버 컴파일러에서 기본으로 활성화

=== 공통 하위 표현식 제거

[quote]
표현식 E 가 이미 평가되었고 E 에 등장하는 모든 변숫값이 평가 이후 변하지 않는다면, 뒤에 등장하는 E 를 공통 하위 표현식이라고 한다

다시 계산할 필요 없이 이전 계산 결과로 치환

* 지역 공통 하위 표현식 제거: 적용 범위가 기본 블록으로 제한
* 전역 공통 하위 표현식 제거: 둘 이상의 기본 블록에 걸쳐 있음

int d = (c * b) * 12 + a + (a + b * c); +
int d = E * 12 + a + (a + E); +
int d = E * 13 + a + a;

=== 배열 경계 검사 제거

== 실전: 그랄 컴파일러 깊이 이해하기

고성능, 메모리 사용량 감소, 폴리글랏 프로그래밍, AOT 네이티브 컴파일

=== 역사적 배경

* JAVA 언어로 작성
** 코드가 명확하고, hotspot 컴파일러의 다양한 고급 최적화 기술을 가져와 쓸 수 있었음
* JIT 컴파일러 인터페이스 (JVMCI) 가 나오게 되어 컴파일러 대체가 쉬워짐
.. hotspot VM 의 컴파일 요청에 응답, 요청을 자바로 구현된 JIT 컴파일러에 전달
.. hotspot JIT 컴파일 관련 데이터를 자바 언어 수준의 데이터 구조로 제공
.. hotspot 코드 캐시 추상화 -> 컴파일러가 컴파일이 끝난 네이티브 코드를 배포할 수 있음

=== JVMCI 컴파일러 인터페이스

* 입력: 컴파일할 메소드의 바이트코드 (byte[])
* 출력: 네이티브 코드 (byte[])

=== 코드 중간 표현

* bytecode -> ideal graph -> optimization -> native code
* ideal graph
** 노드 - 변수, 연산자, 메소드, 필드 등의 프로그램 요소 표현
** 엣지 - 데이터나 제어 흐름 표현
** 점선 - 코드 흐름, 실선 - 실행 순서
