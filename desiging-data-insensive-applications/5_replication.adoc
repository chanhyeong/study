= 5. 복제

네트워크로 연결된 여러 장비에 동일한 데이터의 복사본을 유지

* 지리적으로 사용자와 가깝게 데이터 유지 - 지연 시간 줄이기
* 가용성
* read 장비 확장 - 처리량 증가

이 장에서 볼 것들

* 세 가지 알고리즘: single-leader, multi-leader, leaderless
* 동기식 복제, 비동기식 복제
* 잘못된 복제본을 어떻게 처리할지
* eventual consitency
* read-your-write (쓰기 읽기), monotonic read (단조 읽기)

== Leader, 팔로워

replica - 복제 서버

. client: 리더에게 write 요청
. 리더가 데이터 변경을 replication log or change stream 의 형태로 팔로워 에게 전송
. 팔로워: 리더가 처리한 것과 동일한 순서로 모든 write 를 적용

(복제 지연이 있을 수 있어서, write 직후 조회는 master 로 했던 경험도..)

=== 동기식, 비동기식 복제

동기식은 비현실적이다 - 임의 노드의 장애가 전체 시스템을 멈추게 함

반동기식 (semi-synchronous): 리더 + 하나의 동기식 팔로워 +
보통은 완전히 비동기식으로 구성

=== 새로운 팔로워 설정

새로운 팔로워 가 리더의 데이터 복제본을 정확히 가지고 있는지 어떻게 보장할지?

중단 없이 팔로워 설정을 하는 순서

. 리더 DB 스냅샷을 일정 시점에 가져옴 (DB 백업 기능으로)
. 스냅샷을 새로운 팔로워 노드에 복사
. 팔로워 가 스냅샷 이후 변경을 리더에게 요청
. 따라잡음: 스냅샷 이후 backlog 처리했을 때
** 리더에 발생하는 데이터 변화를 이어 처리

=== 노드 중단 (Outage) 처리

==== 팔로워 장애: 따라잡기 복구

결함 발생 전 마지막 트랜잭션을 구함 -> 리더에 연결하여 끊어진 동안 발생한 데이터 변경 요청

==== 리더 장애: 장애 복구

팔로워 중 하나를 새로운 리더로 승격 -> 리더로 전송하기 위해 재설정 +
= failover

자동 failover 순서

. 리더 장애 여부 판단
** 일정 시간 응답이 없으면 죽은 것으로 간주
. 새로운 리더 선출
. 새로운 리더 사용을 위해 시스템 재설정

잘못될만한 포인트들

* 새로운 리더가 이전 리더의 쓰기 일부를 수신하지 못할 수 있음
** 이전 리더에 복제되지 않은 write 를 단순 폐기할 수 있음 - tolerance 기대를 버림
** 폐기 부작용 - Github 사고
* split brain: 둘 다 리더라고 주장하는 경우
** 두 리더가 write 충돌을 해소하는 과정이 없으면 데이터가 유실되거나 오염
** 일부 시스템에는 하나를 죽이는 매커니즘이 있는데, 잘못하면 둘 다 죽일 수도

=== 복제 로그 구현

==== 구문 (stetement) 기반 복제

SQL 을 그대로 파싱 

문제점

* NOW(), RAND() 구문이 다른 값이 될 수 있음
** 미리 고정 값을 반환하게 대체할 수도
* AUTO_INCREMENT: 모든 구문이 정확히 같은 순서로 실행되어야
* trigger, stored procedure 등은 부작용이 발생할 수도

MySQL 은 row-based 복제를 사용

==== Write-ahead log (WAL) 배송

* LS 저장소 엔진은 로그 자체가 저장소의 주요 부분 - 작게 유지, 백그라운드 가비지 컬렉션
* B tree 에서 모든 변경은 WAL 에 쓰기 - 고장 이후 일관성 있는 상태로 복원

로그 = append-only

완전히 동일한 로그로 다른 노드에서 복제 서버를 구축할 수 있다 +
팔로워 에게 로그를 전송하기도 한다

PostgreSQL, Oracle

로그가 제일 저수준의 데이터를 기술한다 - 어떤 디스크 블록에서 어떤 바이트 변경 +
복제가 저장소 엔진과 밀접하게 엮임

복제 프로토콜이 버전의 불일치를 허용하지 않는다면 업그레이드 시 중단이 필요 +
(카프카에서 버전 호환되게 롤링 업그레이드 하는거와 비슷하게 해야 한다)

==== logical (row-based) log 복제

복제 (logical) 와 저장소 엔진 (physical) 에 다른 로그 형식을 사용

* INSERT 로그: 모든 컬럼의 새로운 값을 포함
* DELETE 로그: PK 포함, PK 가 없으면 모든 컬럼의 예전 값을 로깅
* UPDATE 로그: PK & 모든 컬럼의 새로운 값

transaction 의 경우 마지막에 커밋됐음을 레코드에 표시

하위 호환성을 쉽게 유지할 수 있다 +
리더, 팔로워 에서 다른 버전 DB 나 다른 저장소 엔진을 실행할 수 있다

파싱하기 쉽다 - CDC

==== trigger 기반 복제

유연성이 필요한 상황: 데이터의 서브셋만 복제, DB 를 다른 종류의 DB 로 복제

Oracle GoldenGate: db log 를 읽어서 애플리케이션이 데이터를 변경할 수 있게 함 +

trigger or stored procedure

애플리케이션 코드를 등록할 수 있게 - 데이터가 변경되면 자동으로 실행 +
데이터 변경을 분리된 테이블에 로깅 - 이 테이블로부터 데이터 변경을 외부 프로세스가 읽음 +
외부 프로세스가 다른 시스템으로 데이터 변경 복제

Oracle 용 Databus, PostgreSQL 용 Bucardo

오버헤드가 크고, 버그나 제한 사항이 더 많이 발생

== 복제 지연 문제

팔로워 가 뒤처지면 불일치할 수도

=== 자신이 쓴 내용 읽기

데이터를 자주 읽지만 가끔 쓰는 경우

write after read 일관성을 구현

* 사용자가 수정한 내용을 읽을 때는 리더 에서 읽음
** 대량의 내용을 사용자가 편집할 수 있다면 효율적이지 않음
** 마지막 갱신 시간 후 1분 동안은 리더 에서 모든 읽기 수행
** or 1분 이상 늦은 팔로워 에 대한 질의 금지
* client 에서 마지막 쓰기 타임스탬프 기억 - 복제 서버가 최신 내용이 아니면 다른 복제 서버가 읽기 or 대기
* 복제 서버가 여러 데이터센터에 복제됐다면 복잡함
** 리더가 제공해야 하는 모든 요청은 리더가 포함된 데이터센터로 라우팅

=== monotonic read

개별 복제 DB 에서 조회하는 경우 '시간이 거꾸로 흐르는' (조회됐다가 안됐다하는) 현상이 있을 수도

데이터를 읽을 때 이전 값을 볼 수 있게 +
개별 사용자마다 특정 기준으로 해시하여 복제 서버를 선택하게

=== 일관된 순서로 읽기 (Consistent Prefix Read)

복제 순서가 뒤바뀐 경우, 보통 파티셔닝된 DB 에서 발생하는 특징적인 문제

파티션이 독립적으로 동작하여 write 순서가 섞이는 문제

서로 인과성이 있는 쓰기가 동일한 파티션에 기록되게 한다 +
인과성을 명시적으로 유지하기 위한 알고리즘도 있다

==== 복제 지연을 위한 해결책

복제가 비동기식으로 동작하지만 동기식으로 동작하는 척 보이게 만들어야 한다

== 다중 리더 복제

multi-leader (master master, active/active) +
write 를 받는 노드는 변경을 다른 모든 노드에 전달

리더이면서 다른 리더의 팔로워

=== 다중 리더 복제의 사용 사례

==== 다중 데이터센터 운영

데이터센터마다의 리더 +
데이터센터 내에서는 single 리더 +
데이터센터 간에는 리더가 다른 리더의 변경을 복제

MySQL - Tungsten Replicator (confluent) +
PostgreSQL - BDR +
Oracle - GoldenGate

**동일한 데이터를 동시에 변경할 수 없다 - 쓰기 충돌을 해소해야 한다**

auto increment key, trigger 등이 문제될 수도 +
가능하면 피해야 하는 위험한 영역으로 간주되기도 한다

==== 오프라인 작업을 하는 클라이언트

인터넷 연결이 끊어진 동안 애플리케이션이 계속 동작해야 하는 경우 +
(휴대전화, 노트북, 디바이스 캘린더 앱)

리더처럼 동작하는 로컬 DB +
동작은 위에 설명한 것과 동일

==== 협업 편집

로컬 복제 서버에 적용 -> 다른 사용자와 서버에 비동기 방식으로 복제

변경 단위를 매우 작게 해서 lock 을 피할 수 있음. 충돌은 해소해야 함

=== 쓰기 충돌 다루기

==== sync vs async 충돌 감지

동기식은 단일 리더 복제만 사용해야 할 수 있다 (각 복제 서버가 독립적인 쓰기를 할 수 없으므로)

충돌 감지는 async 로

==== 충돌 회피

애플리케이션 단: 특정 레코드의 모든 쓰기가 동일한 리더를 거치도록

(서로 다른 위치의 사용자가 동일한 레코드를 수정한다면, 지리적 이점은 포기하고 가는건가?0

==== 일관된 상태 수렴 (convergent)

쓰기 순서가 정해지지 않아 최종 값이 무엇인지 명확하지 않음 (그림 5-7)

* 고유 ID 를 가진 쓰기를 고르고 다른 쓰기는 버림
** last write wins (LWW)
* 개별 복제 서버에 고유 ID 부여 - 높은 숫자를 항상 우선적으로
* 어떻게든 병합
* 명시적 데이터 구조에 충돌을 기록 = 모든 정보를 보존 -> (사용자에게 보여주고) 나중에 충돌을 해소하는 애플리케이션 코드 작성

==== 사용자 정의 충돌 해소 로직

* 쓰기 수행 중
** 충돌 감지 즉시 충돌 핸들러 호출
* 읽기 수행 중
** 충돌 감지 시 모든 충돌 쓰기를 저장
** 다음 read 시점에 여러 버전의 데이터가 애플리케이션에 반환 - 충돌 내용을 보여주거나 자동 해소

충돌 해소는 전체 트랜잭션이 아니라 개별 로우나 문서 수준에서 적용 +
atomic 하게 다수의 쓰기가 있는 트랜잭션이라면, 각 쓰기는 충돌 해소를 별도로

.자동 충돌 해소
****
아마존 - 추가된 상품 보존, 삭제한 상품을 보존하지 않음 +
상품을 삭제했어도 다시 보이기도

데이터를 수정할 때 발생하는 충돌을 자동으로 해소하는..

* conflict-free replicated datatype, CRDT
** set, map, sorted list, counter
** two-way merge
* mergable persistent data structure
** git 과 유사한, three-way merge function
* operational transform
** 충돌 해소 알고리즘. 정렬된 항목 목록의 동시 편집을 위해 설계
****

=== 다중 리더 복제 토폴로지

복제 토폴로지: 쓰기를 한 노드 -> 다른 노드로 전달하는 통신 경로

all-to-all, circular, star

circular, star 에서는 여러 노드를 거쳐야 모두 복제 된다 +
하나의 노드에 장애가 발생하면 다른 노드 간 복제를 방해 -> 보통은 수동 재설정이 필요해서 all-to-all 이 좋다

all-to-all 에서는 특정 네트워크 연결이 다른거보다 빠르면 일부 복제 메시지가 다른 메시지를 추월할 수 있다 +
-> version vector 도입

== 리더 없는 복제

leaderless, Dynamo style

클라이언트가 write 요청을 전송 -> DB 시스템이 write 를 다른 복제 서버에 복사 +
리더가 write 처리하는 순서를 정하고 팔로워는 동일한 순서로 리더의 write 를 적용

모든 복제 서버가 클라이언트로부터 write 를 직접 받을 수 있다

Dynamo, Riak, Cassandra, Voldemort

coordinator node 가 클라이언트를 대신해 수행하기도 - 특정 순서로 write 를 수행하진 않음

=== 노드가 다운됐을 때 DB write

==== 읽기 복구와 안티 엔트로피

사용 불가능 -> 온라인 됐을 때 누락된 write 를 어떻게 따라 잡는가?

* 읽기 복구
** 클라이언트가 여러 노드에서 병렬로 읽기 -> 오래된 응답 감지
** 값이 오래된 것을 알고 해당 복제 서버에 새로운 값을 다시 기록
** 값을 자주 읽는 상황에 적합
* 안티 엔트로피 처리
** 백그라운드 프로세스에서 복제 서버 간 데이터 차이를 지속적으로 찾음 -> 누락된 데이터를 복사
** 순서를 가지고 write 복사하기 때문에 지연이 있을 수 있다

==== 일기과 쓰기를 위한 정족수 (quorum)

n 개의 복제 서버가 있을 때, 쓰기가 w 개의 노드에서 성공해야 확정, 읽기는 r 개의 노드에 질의

`w + r > n` 이면 최신 값을 얻을 것으로 기대 +
이를 만족하면

* w < n 이어도 write 가능
* r < n 이어도 read 가능
* 일반적으로 read/write 는 항상 모든 n 개의 복제 서버에 병렬로 전송
** w, r 은 얼마나 많은 노드를 기다릴지 결정. n 개 중 몇 개에서 성공을 확인해야 하는지를 나타낸다

=== 정족수 일관성의 한계

w, r 을 과반수보다 적게 할 수 있고 작을 수록 오래된 값을 읽을 수 있다

과반 수인 경우에도 오래된 값을 반환하는 엣지 케이스가 있다

* 느슨한 정족수 (p184) -> w 개의 쓰기와 r 개의 읽기가 겹치지 않을 수 있음
* 두 개의 쓰기가 동시에 발생하면 어떤 쓰기가 먼저였는지 잘 모름 - 동시 쓰기 감지 (p186) 하여 합치기
* write, read 가 동시에 발생하면 write 가 일부에만 반영 -> read 가 예전 값인지 최신 값인지 분명하지 않음 (?)
* write 가 일부만 성공하고 일부가 실패했을 때 성공한 서버가 w 보다 적으면 성공한 복제 서버를 롤백하지 않는다 (?)
* 새 값을 전달하는 노드가 고장나면 예전 값을 가진 다른 복제 서버에서 복원, 새 값을 저장한 복제 서버 수가 w 보다 낮아져서 정족수 조건이 깨짐
* 이 외 p331 선형성과 정족수

견고한 보장을 위해 트랜잭션이나 합의가 필요 (7장, 9장)

==== 최신성 모니터링

복제 서버의 오래됨 (staleness) 를 측정하여 표준 지표 셋에 추가

(아직까진 정해진 답은 없는 듯)

=== 느슨한 (Sloppy) 정족수와 암시된 (Hinted) 핸드오프

* w, r 정족수를 만족하지 않는 모든 요청에 오류 반환?
* 일단 write 를 받아서 (n 개 노드에 속하지 않는) 연결할 수 있는 노드에 기록? (느슨한 정족수)
** 장애가 끝나면 일시적으로 수용한 모든 write 를 해당 홈 노드로 전송 (암시된 핸드오프)

데이터가 w 노드 어딘가에는 저장된다 (?, (n 개 노드에 속하지 않는) 연결할 수 있는 노드에 기록하는데 n 은 w 를 포함하는 개념이 아닌가?) +
암시된 핸드오프가 완료될 때까지는 r 노드의 읽기가 저장된 데이터를 본다는 보장이 없음

==== 다중 데이터 센터 운영에 적합하다

=== 동시 쓰기 감지

==== 최종 쓰기 승리 (동시 쓰기 버리기)

가장 최신 값으로 덮어 쓰기

write 는 자연적인 순서가 없지만, 임의로 순서를 정할 수 있다 - 타임스탬프 붙이기 +
LWW

LWW 는 동시 write 가 아니라도 write 가 삭제될 수 있다 - p291 이벤트 순서화용 타임스탬프

손실 데이터를 허용하지 않는다면 적합하지 않다

베스트 케이스는 키를 한 번만 쓰고 immutable 하게 다루기 - 같은 키를 동시에 갱신하는 상황 방지

==== "이전 발생" (happen-case) 관계와 동시성

동시에 수행됐는지 여부를 어떻게 결정?

* 인과성이 있는 (casually dependent) 작업
* 인과성이 없는 작업

두 작업이 있을 때 케이스: A -> B or B -> A or A, B

두 작업의 동시성 여부를 알 수 있는 알고리즘이 필요하다 +
인과성이 있다면? -> 덮어 쓰기 +
인과성이 없다면? -> 충돌 해소

==== 이전 발생 관계 파악하기

* 서버가 모든 키에 대한 버전 번호 유지, 키를 기록할 때마다 버전 번호 증가, 기록한 값은 새로운 버전 번호를 가지고 저장
* 클라이언트가 키를 읽을 때는 덮어쓰지 않은 모든 값 반환
* 클라이언트가 키를 기록할 때는 이전 읽기의 버전 번호 포함, 이전 읽기에서 받은 모든 값을 합침
** (서버에선 삭제됐는데 읽어간거에서는 남아있으면 어떻게?, 아래 tombstone 인가)
* 서버가 특정 번호를 가진 쓰기를 받을 때, 해당 버전 이하 모든 값을 덮어 쓸 수 있다, 높은건 유지해야 한다

==== 동시에 쓴 값 병합

동시에 쓴 값을 합쳐 정리해야 한다

Riak 에서는 sbiling value 라고 부른다

추가 외에 제거도 할 수 있게 하려면 +
두 개를 합치고 나서 하나를 제거할 때, 제거했음을 나타내기 위해 해당 버전 번호에 표시 - tombstone

==== 버전 벡터

복제본당 버전 번호 - 각 복제본이 write 처리 시 자체 버전 번호 증가, 다른 복제본의 버전 번호도 추적 +
version vector: 모든 복제본의 버전 번호 모음

하나의 복제본을 읽어서 다른 복제본에 다시 쓰는 작업이 안전함을 보장하기 때문에 형제가 생성돼도 형제가 올바르게 병합되는 한 데이터 손실이 없다