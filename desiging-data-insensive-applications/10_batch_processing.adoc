= 10. 일괄 처리

:toc:

(파트3 파생 데이터 내용)

데이터 모델이 다르고 접근 양식이 다른 데이터 시스템을 일관성 있는 하나의 애플리케이션 아키텍처로 통합하는 문제 검토

레코드 시스템 (source of truth) - 믿을 수 있는 데이터 버전 저장 +
파생 데이터 시스템 - 다른 시스템의 데이터를 가져와서 변환하고 처리한 결과. 데이터를 잃어도 원천에서 다시 생성할 수 있음

---

온라인 시스템 - 응답 시간 단축에 노력

* 서비스 (온라인 시스템): request - response
* 일괄 처리 시스템 (오프라인 시스템): 매우 큰 입력 데이터 -> 처리 작업 수행하여 결과 데이터 생산
** 수 분 ~ 수 일, 처리량이 주요 성능 지표
* 스트림 처리 시스템 (준실시간 시스템): 요청에 대해 응답하지 않음음. 입력 데이터 소비 - 출력 데이터 생산

== 유닉스 도구로 일괄 처리하기

* 정렬 vs 인메모리 집계

작업 세트가 작으면 인메모리 해시 테이블도 잘 동작 +
작업 세트가 크다면 정렬 접근법을 사용 +
(sort 는 메모리보다 큰 데이터 셋을 자동으로 디스크로 보내고, CPU 코어에서 정렬)

=== 유닉스 철학

유닉스 파이프 - 다른 방법으로 데이터 처리가 필요할 때 여러 다른 프로그램을 연결하는 방법이 필요하다 +
배관 공사와 비슷하여 파이프로 명명

. 각 프로그램이 한 가지 일만 하도록 작성
. 모든 프로그램의 출력이 다른 프로그램의 입력으로 쓰일 수 있다고 생각
. 소프트웨어를 빠르게 써볼 수 있게 설계, 구축
. 작업을 줄이려면 미숙한 도움보단 도구를 사용

==== 동일 인터페이스

프로그램들 간의 연결이 가능하게 하려면 모두가 같은 입출력 인터페이스를 사용해야 한다

유닉스에서는 파일 (파일 디스크립터)

==== 로직과 연결의 분리

파이프는 한 프로세스의 stdout 을 다른 프로세스의 stdin 과 연결 - 인메모리 버퍼 사용

프로그램은 입력이 어디서부터 들어오는지 출력이 어디로 나가는지 신경쓰거나 알 필요가 없음 -> 입출력 연결이 분리되어 작은 도구로 큰 시스템 구성이 훨씬 수월 +
(loose coupling, late binding, inversion of control)

제약사항: 프로그램이 여러 입출력을 처리하기가 까다로움, 네트워크 연결하지 못함 (단일 장비)

==== 투명성과 실험

입력이 불변, 어느 시점이든 중단 가능하여 출력 확인, 특정 단계의 출력을 파일에 기록하고 다음 입력으로 사용할 수 있음

== 맵리듀스와 분산 파일 시스템

유닉스 도구와 비슷하지만 다수의 장비로 분산해서 실행 가능 +
입력 수정 없이 출력 생산 +
분산 파일 시스템 상의 파일을 입출력으로 사용

HDFS - 비공유 원칙 기반. 개발 장비의 데몬 프로세스에서 네트워크 서비스 제공 +
NameNode: 특정 파일 블록이 어떤 장비에 저장됐는지 추적하는 중앙 서버

=== 맵리듀스 작업 실행하기

맵리듀스: 분산 파일 시스템 위에서 대용량 데이터셋을 처리하는 코드를 작성하는 프로그래밍 프레임워크

. 읽고 레코드로 쪼갬 (구분자 \n)
. 레코드마다 매퍼 함수 호출, key-value 추출
. key 를 기준으로 정렬
. key-value 페어 전체를 대상으로 리듀스 함수 호출

Mapper: 입력 레코드에서 key, value 를 추출하는 작업 (데이터 준비) +
Reducer: key-value 페어를 받아 같은 key 를 가진 레코드를 모으고 값의 집합을 반복해 Reducer 함수 호출. 출력 레코드 생산 (데이터 가공)

==== 맵리듀스의 분산 실행

그림 10-1 +
병렬 실행 - 파티셔닝을 기반 +
입력 = 디렉토리, 디렉토리 내 각 파일 or 파일 블록을 독립 파티션으로 간주

복제본이 있는 장비에 리소스 여유가 있으면 스케줄러가 입력 파일이 있는 장비에서 작업을 수행하려고 한다 = **데이터 가까이에서 연산하기** (Put the computation near the data)

애플리케이션 코드는 작업 수행 전 복사된다

리듀서 쪽 연산도 파티셔닝 +
리듀서 태스트 수는 사용자가 설정 -> 맵, 리듀스 태스크 수는 다를 수 있다

셔플: 리듀서를 기준으로 파티셔닝, 정렬. 매퍼로부터 데이터 파티션을 복사하는 과정

리듀스 시 매퍼로부터 파일을 가져와서 정렬된 순서를 유지하며 병합

==== 맵리듀스 워크플로

맵리듀스 작업을 연결하기

하둡 맵리듀스 작업 간 수행 의존성을 관리하기 위한 스케줄러들 - Oozie, Azkaban, Luigi, Airflow, Pinball

다중 맵리듀스를 적절하게 자동으로 엮어 워크플로 설정하는 고수준 도구 - Pig, Hive, Cascading, Crunch, FlumeJava

=== 리듀스 사이드 조인과 그룹화

foreign key, document reference, edge

맵리듀스에서는 일반적인 인덱스 개념이 없다. full table scan

==== 사용자 활동 이벤트 분석 예제

일괄 처리 처리량을 위해서는 한 장비 내에서 연산을 수행해야 한다

==== 정렬 병합 (sort-merge) 조인

그림 10-3. 사용자 DB 와 활동 DB 에서 각각 key-value 추출

리듀서가 로컬 변수에 생년월일 저장 -> 같은 사용자 id 이벤트 순회

매퍼 출력이 키로 정렬 -> 리듀서가 약측의 정렬된 레코드 목록을 병합

(중간에 비어있는 키들에 대해서는 어떻게?)

==== 같은 곳으로 연관된 데이터 가져오기

매퍼와 정렬 프로세스는 특정 key 로 조인 연산을 할 때 필요한 모든 데이터를 한 곳으로 모은다 = key 별로 리듀서를 한 번만 호출

필요한 데이터를 정렬해뒀기 때문에 리듀서는 단일 스레드로 동작하는 코드 조각이 될 수 있다

장비로 데이터를 모으는 연산 (물리적 네트워크 연산) 과 데이터를 처리하는 애플리케이션 로직을 분리

==== 그룹화

단순: key-value 를 생성할 때 키로 그룹화

특정 사용자의 일련의 활동을 찾기 위해 세션별 활동 이벤트 수집 - 세션화

==== 쏠림 (hotspot) 다루기

linchpin object, hot key

* Pig - skewed join
** 어떤게 hot key 인지 결정하기 위해 샘플링
** 실제 조인 시 hot key 를 가진 레코드는 여러 리듀서 중에 임의의 하나로 보냄
** hot key 로 조인할 다른 입력은 모든 리듀서에 복제 - 복제 비용이 크지만 병렬화 효과가 크다
* Crunch - shared join
** 샘플링 작업 대신 hot key 를 명시적으로 지정
* Hive - map-side join
** 테이블 메타데이터에 명시적으로 지정, hot key 와 관련된 레코드를 별도 파일에 저장

그룹화 -> 집계

. 레코드를 임의의 리듀서로 보내서 hot key 레코드의 일부 그룹화 -> key 별로 집계하여 출력
. 위 단계에서 나온 값을 key 별로 모두 결합하여 하나의 값으로 만듦

=== 맵 사이드 조인

이전은 조인 로직을 리듀서에서 수행

데이터에 대한 특정 가정이 필요 없는 장점 +
정렬 후 복사, 병합 비용이 큰게 단점

데이터에 대해 특정이 가능하다면 맵사이드 조인으로 더 빠르게 수행할 수 있다

매퍼는 파일을 읽어 출력하는게 전부

==== 브로드캐스트 해시 조인

작은 데이터셋과 매우 큰 데이터셋을 조인하는 경우

데이터를 읽어서 인메모리 해시에 넣고 -> 다음 데이터를 스캔할 때 해시 테이블에서 간단하게 조회

큰 input 의 파티션 하나를 담당하는 각 매퍼는 작은 input 전체를 읽는다

==== 파티션 해시 조인

조인의 input 을 파티셔닝하고 해시 조인 접근법을 각 파티션에 독립적으로 적용

조인할 레코드들이 같은 파티션에 위치 +
각 매퍼의 해시 테이블에 적재해야 할 데이터 양을 줄일 수 있는게 장점

==== 맵 사이드 병합 조인

데이터셋이 같은 방식으로 파티셔닝 & 같은 key 를 기준으로 정렬됐다면

오름차순으로 양쪽 입력 모두를 점진적으로 읽어 키가 동일한 레코드를 맞춘다 +
(= 선행 맵리듀스 작업이 이미 파티셔닝 & 정렬해두었다)

==== 맵 사이드 조인을 사용하는 맵리듀스 워크플로

맵 사이드 조인 시 크기, 정렬, 입력 데이터의 파티셔닝 등의 제약 조건 +
조인 전략 최적화 시 분산 파일 시스템 내 저장된 데이터셋의 물리적 레이아웃 파악이 중요하다

파티션 수가 몇 개, 데이터가 어떤 키를 기준으로 파티셔닝 & 정렬