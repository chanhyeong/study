= 8. 분산 시스템의 골칫거리

현업에서 일어나는 문제점들 & 기댈 수 있는 것과 아닌 것을 볼 예정

== 결함과 부분 장애

단일 컴퓨터에서는 같은 연산은 같은 결과. 결정적

partial failure: 분산 시스템에서 어떤 부분은 잘 동작하지만, 예측할 수 없는 방식으로 다른 부분이 고장나는 경우 +
비결정적 (Nondeterministic) 이어서 어렵다 - 어떨 때는 동작, 어떨 때는 실패

=== 클라우드 컴퓨팅과 슈퍼컴퓨팅

두 개는 양 극단에 있다 (단일 노드에 엄청난 성능 / 네트워크에 걸친 여러 노드) +
전통적인 기업형 데이터센터는 중간 지점에 있다

분산 시스템이 동작하게 만드려면 부분 장애 가능성을 받아들이고, 내결함성 메커니즘을 넣어야 한다 +
== 신뢰성 없는 구성 요소를 사용해 신뢰성 있는 시스템을 구축해야

결함 처리는 소프트웨어 설계의 일부여야, 결함이 발생하면 어떻게 동작하지 알아야

(가능성이 낮아도) 결함을 광범위하게 고려, 테스트 환경에서 인위적으로 상황을 만들어서 어떤 일이 생기는지 보는게 중요

.신뢰성 없는 구성 요소를 사용해 신뢰성 있는 시스템을 구축
****
오래된 아이디어들

* 오류 수정 코드 (error-correcting code)
* IP (Internet Procotol) 는 신뢰성이 없어, TCP 는 IP 위에서 신뢰성이 높은 전송 계층을 제공
****

== 신뢰성 없는 네트워크

네트워크는 장비들이 통신하는 유일한 수단 +
장비는 고유의 메모리와 디스크를 가지고, 다른 장비에서 접근할 수 없음

인터넷, 데이터센터 내부 네트워크 대부분은 비동기 패킷 네트워크다

. 요청이 손실될 수 있음
. 큐에 대기하다 나중에 전송될 수 있음
. 원격 노드가 장애가 생겼을 수도
. 원격 노드가 일시적으로 응답을 멈췄다 나중에 다시 응답할 수도
. 원격 노드가 요청을 처리했지만 응답이 네트워크에서 손실됐을 수도
. 원격 노드가 요청을 처리했지만 응답이 지연되다가 나중에 전송될 수도

=== 현실의 네트워크 결함

네트워크 분단 (partition) or 분리 (netsplit) +
-> 네트워크 결함 때문에 네트워크 일부가 다른 쪽과 차단되는 것

네트워크 결함이 드물더라도 일어날 수는 있으므로, 소프트웨어가 처리할 수 있어야 한다

네트워크에 문제가 있을 때 그냥 사용자에게 오류 메시지를 보여주는 것도 타당한 방법이지만 +
소프트웨어가 어떻게 반응할지 알고 시스템이 복구할 수 있도록 보장해야 한다

카오스 몽키: 고의로 네트워크 문제를 유발하고 시스템의 반응을 테스트

=== 결함 감지

* LoadBalancer 는 죽은 노드로 요청을 그만 보내야 한다
* 단일 리더 복제에서 리더가 죽으면 팔로워가 리더로 승격되어야 한다

네트워크 불확실성 때문에 노드가 동작 중인지 아닌지 구별이 어려운 문제

요청이 성공했음을 확신하려면 애플리케이션 자체에서 긍정 응답을 받아야 한다

몇 번 재시도를 해보고 타임아웃이 만료되기를 기다렸다가, 타임아웃 내에 응답을 받지 못하면 죽은거로 선언할 수도 있다

=== 타임아웃과 기약 없는 지연

타임아웃 설정에 간단한 답은 없다

노드가 죽었다면, 해당 노드의 일이 다른 노드로 전달 -> 다른 노드와 네트워크에 추가적인 부하 -> 연쇄 장애

모든 패킷은 어떤 시간 a 내에 전송/손실 & 전송 시간이 d 보다 더 걸리진 않는다 +
장애가 나지 않은 노드는 요청을 r 시간 내에 처리한다는 보장 +
-> 2d + r 을 타임아웃으로 사용

보통 아무것도 보장되지 않음. 기약없는 지연이 있음 +
타임아웃이 낮으면 왕복 시간 (RTT) 이 순간적으로 급증해도 시스템의 균형을 무너뜨림

==== 네트워크 혼잡과 큐 대기

네트워크 패킷 지연의 변동성은 큐 대기 때문인 경우가 많다

* 네트워크 혼잡 (congestion): 네트워크 링크가 붐비면 패킷은 슬롯을 얻을 수 있을 때까지 잠시 기다려야 한다 (그림 8-2)
* 리소스 부족 시 운영체제가 패킷을 큐에 넣어둠
* vm 에서는 다른 vm 이 cpu 사용 동안 멈출 때, 큐에 넣어 버퍼링
* TCP 흐름제어: congestion avoidance, backpressure
** 과부하를 가하지 않도록 자신의 송신율을 제한

TCP 는 타임아웃 안에 확인 응답을 받지 않으면 패킷이 손실됐다고 간주하고 손실된 패킷을 자동으로 재전송

클라우드에서는 여러 소비자가 자원을 공유 (네트워크 링크, 스위치, 장비 네트워크 인터페이스, ...) +
자원을 많이 사용하는 누군가가 있다면 네트워크 지연 변동이 클 수 있다

실험적인 타임아웃 선택 -> RTT 분포 측정 -> 트레이드오프 결정 (장애 감지 지연 - 너무 이른 타임아웃)

고정된 타임아웃 설정 대신 시스템이 지속적으로 응답 시간과 변동성 (jitter) 을 측정하고 +
타임아웃을 자동으로 조절하게 하는 것 +
ex) Phi Accural failure detector (Akka, 카산드라에서 사용), TCP 재전송 타임아웃

=== sync vs async network

전화에서는 회선 (circuit) 이 만들어진다 - 고정되고 보장된 양의 대역폭 할당 +
bounded delay (제한있는 지연)

==== 네트워크 지연을 예측 가능하게 만들기?

TCP 연결은 가용한 네트워크 대역폭을 기회주의적으로 사용 +
유휴 상태라면 어떤 대역폭도 사용하지 않음 (keepalive 가 켜져있으면 제외)

이더넷과 IP 는 큐 대기의 영향을 받는 packet-switch 프로토콜, 네크워크에 기약없는 지연이 있다

패킷 교환 - 순간적으로 몰리는 트래픽에 최적화 (busty traffic)

ATM (asynchronous tranfer mode): circuit, packet 교환을 모두 지원하는 하이브리드 네트워크 +
QoS 를 잘 쓰면 패킷 네트워크에서 회선 교환을 흉내 내거나, 제한 있는 지연을 제공하는 것도 가능 +
-> 멀티 테넌트 데이터센터, 공개 클라우드에서 사용할 수 없고, 인터넷 통신에서도 사용할 수 없음

== 신뢰성 없는 시계

시계에 의존하는 경우들 - 지속 시간을 측정 or 시점을 기술

통신이 즉각적이지 않으므로 시간을 다루기 까다로움 +
개별 장비는 자신의 시계를 갖고 있다 (quartz crystal oscillator)

동기화 메커니즘 - NTP (Network Time Protocol)

=== 단조 (monotonic) 시계 vs 일 기준 (time-of-day) 시계

==== time-of-day clock (wall-clock time)

달력에 따라 현재 날짜와 시간 반환

`clock_gettime(CLOCK_REALTIME)` (Linux), `System.currentTimeMillis()` (JAVA) - epoch (19700101) 이래로 흐른 초 수를 반환. 윤초 무시

NTP 로 동기화

로컬 시계가 NTP 서버보다 앞서면 강제로 리셋되어 거꾸로 뛰는 것처럼 보일 수 있다 +
윤쵸 무시와 더불어 경과 시간 측정에는 적합하지 않음

매우 거친 (coarse-grained) 해상도를 가진다 - 옛날 윈도우 시스템에서는 10ms 단위로 흐른다

==== monotonic clock

이름의 유래 - 시간은 항상 앞으로 흐른다 (일 기준에선 거꾸로 뛸 수도 있다)

타임아웃이나 서비스 응답 시간 등 지속 시간을 재는 데 적합

`clock_gettime(CLOCK_MONOTONIC)` (Linux), `System.nanoTime()` (JAVA)

한 시점에서 단조 시계 확인, 나중에 다시 확인 -> 두 값의 차이로 시간 확인 _
시계의 절대적인 값은 의미가 없다 & 두 대의 다른 컴퓨터에서 나온 단조 시계 값을 비교하는 것은 의미가 없다 (동일하지 않다)

NTP 는 로컬 시계가 NTP 와 맞지 않는걸 발견하면 단조 시계가 진행하는 진도수를 조정할 수 있다 (slewing) +
시계 속도를 0.05% 까지 올리거나 내리는 것을 허용하지만, 앞이나 뒤로 뛰게 할 수는 없다 +
해상도가 좋아서 마이크로초나 이하 단위로 측정할 수 있다

=== 시계 동기화와 정확도

* drift 현상 (더 빠르거나 느리게 실행)
** 컴퓨터의 수정 시계는 아주 정확하지는 않다 - 장비의 온도에 따라 변함
* 컴퓨터와 NTP 간 너무 많이 차이가 나면 동기화가 거부되거나 로컬 시계가 강제로 리셋될 수 있다
* 노드와 NTP 가 방화벽으로 막히는 경우
* NTP 동기화는 네트워크 지연에 영향, 혼잡하면 정확도에 한계
* 어떤 NTP 서버들은 이상이 있거나 설정이 잘못되어 차이나는 시간
** 여러 서버에 질의를 보내어 큰 차이가 나는 값을 무시
* 윤쵸가 발생하면 고려하지 않은 시스템에서는 시간에 관한 가정이 엉망이 된다
* vm 에서는 하드웨어 시계도 가상화 - CPU 코어가 공유될 때 다른 vm 이 수행되는 동안 멈춘다 -> 시계가 갑자기 앞으로 뛰는 문제
* 사용자 조작이 가능한 장치 - 고의로 잘못된 시간을 입력

시계 정확도가 중요하다면 맞추기 - 예시로 UTC 와 100 마이크로초 이내로 동기화하기 = 시장 이상 현상 디버깅, 조작 감지

GPS 수신기, 정밀 시간 프로토콜 (PTP) 과 세심한 배포 및 모니터링을 사용하여 달성 +
NTP 데몬 설정이 잘못되거나 방화벽이 NTP 트래픽을 차단하면 시계 오류가 커질 수 있다

=== 동기화된 시계에 의존하기

잘못된 시계에 대비할 필요가 있다

동기화된 시계가 필요한 소프트웨어를 사용한다면, 모든 장비 사이의 시계 차이를 조심스럽게 모니터링해야 한다 +
너무 차이가 많이 나는 노드는 죽은 것으로 선언되어 제거

==== 이벤트 순서화용 타임스탬프

그림 8-3 에서 LWW 로 충돌 해소를 하면 B 의 연산은 손실된다

'최근'의 정의는 로컬 일 기준 시계에 의존하며, 그 시계가 틀릴 수 있다는 것을 아는게 중요하다

NTP 동기화를 정확하게 하기? - 불가능

논리적 시계는 quartz crystal 대신 증가하는 카운터를 기반, 이벤트 순서화의 안전한 대안 +
일 기준 시간이나 경과한 초 수를 측정하지 않고, 상대적인 순서만 측정 +
일 기준/단조 시계는 물리적 시계

==== 시계 읽기는 신뢰 구간이 있다

NTP 서버를 사용하면 최선의 정확도는 수십 ms, 네트워크 혼잡 시 100ms 이상으로 급증

시계 읽기를 특정 시점으로 생각하기보다, 어떤 신뢰 구간에 속하는 시간의 범위로 읽는게 나을 것이다

대부분은 오류 범위의 불확실성을 노출하지 않음 +
Spanner 의 TrueTime API 는 신뢰 구간을 보고한다 (가장 이른/늦은 것을 반환)

==== 전역 스냅샷용 동기화된 시계

DB 가 여러 데이터센터에 분산되어 있을 때는 코디네이션이 필요하므로 전역 단조 증가 트랜잭션 ID 생성이 어려움

동기화된 일 기준 시계의 타임스탬프를 트랜잭션 ID 로 사용

Spanner 는 TrueTime API 의 신뢰 구간을 사용하여 스냅샷 격리 구현 +
인과성을 반영하는 것을 보장하기 위해 읽기 트랜잭션을 커밋하기 전 신뢰 구간 길이만큼 대기 +
각 데이터센터에 GPS 수신기나 원자 시계를 배치하여 시계가 7ms 내로 동기화되게 한다

=== 프로세스 중단

리더만 쓰기를 받는 경우에 노드가 여전히 리더이고 안전하게 쓰기를 받아들일지 어떻게?

다른 노드들로 부터 임차권 (lease) 을 얻기 - 획득하면 리더, 만료되기 전에 갱신

시계 문제와 프로세스 중단 문제가 있을 수 있음 +
-> 분산 시스템은 어느 정도 실행이 멈출 수 있다고 가정해야 한다

==== 응답 시간 보장

중단 원인 제거 방법

소프트웨어가 응답해야 하는 데드라인 명시 +
데드라인 도달 시 전체 시스템 장애를 유발할 수 있다 - 엄격한 실시간 시스템 (hard real-time)

프로세스가 명시된 간격의 CPU 시간을 할당받을 수 있게 보장하도록 스케줄링 - RTOS +

서버측 데이터 처리 시스템에서 실시간 보장은 적절하지 않음

==== GC 영향을 제한하기

* GC 중단을 계호기적으로 중단되는 것으로 간주 -> GC 동안 요청을 다른 노드들이 처리하게
* 수명이 짧은 객체만 GC, 수명이 긴 객체에 대해 GC 전에 주기적으로 프로세스 재시작
** 한 번에 노드 하나씩 재시작 or 롤링

== 지식, 진실, 거짓말

네트워크에 있는 노드는 어떤 것도 확실히 알지 못한다 - 추측만 가능

분산 시스템에서 동작(시스템 모델)에 관해 정한 가정 명시 -> 가정을 만족시키는 방식으로 시스템 설계 +
= 시스템 모델 내에서 알고리즘이 정확하게 동작하는지 증명, 신뢰성 있는 동작 달성

=== 진실은 다수결로 결정된다

분산 알고리즘들은 정족수 (quorum) 에 의해 결정, 보통은 과반수

==== 펜싱 토큰

lock 이 승인될 때마다 증가하는 숫자

그림 8-4 의 문제 해결

lock 서버 - lock 이나 lease 를 승인할 때마다 fencing token 도 같이 반환 +
클라이언트가 요청 시 토큰을 보내고 서버가 유효한 숫자인지 확인

=== 비잔틴 결함

Byzantine fault

없는 환경에서 합의에 도달하는 문제 +
실제로 일어나지 않은 것을 일어났다고 주장함

Byzantine fault-tolerant = 일부 노드가 오작동, 프로토콜을 미준수, 악의적인 공격자가 네트워크를 방해하더라도 시스템 계속 올바르게 동작한다

웹 애플리케이션은 클라이언트의 행동이 랜덤하고 악의적이라고 예상해야 한다 +
input validation, sanitization, output escaping, SQL injection, cross site scripting, ...

==== 약한 형태의 거짓말

하드웨어 문제, 소프트웨어 버그, 잘못된 설정 등

* 오염된 패킷이 TCP, UDP 의 checksum 으로도 안 걸리는 경우 - 애플리케이션 레벨 프로토콜에서 checksum 사용
* 사용자 입력 sanitize
* 여러 서버를 설정한 NTP 클라이언트 - 잘못된 NTP 서버를 동기화 대상에서 제거

=== 시스템 모델과 현실

9장에서 합의 문제 솔루션 볼 예정

시스템 모델: 알고리즘이 가정하는 것을 기술한 추상화 +
알고리즘은 하드웨어/소프트웨어 설정에 심하게 의존하면 안된다

타이밍 가정

* 동기식 모델
** 네트워크 지연, 프로세스 중단, 시계 오차 모두에 상한선이 있다고 가정 = 현실적이지 않음
* 부분 동기식 모델
** 대부분은 동기식 시스템처럼 동작하지만 네트워크 지연, 프로세스 중단, 시계 오차가 가끔 한계치를 초과한다 = 현실적
* 비동기식 모델
** 어떤 가정도 할 수 없다

노드 장애 고려

* crash-stop fault
** 노드가 멈추면 영원히 안 돌아옴
* crash-recovery fault
** 노드가 죽을 수는 있지만 언젠가 다시 돌아올 수 있음
* byzantine fault
** 노드가 다른 노드를 속이거나 기만하는 등 무슨 일이든 할 수 있다

=== 알고리즘의 정확성

알고리즘의 속성을 기술하여 정확하다는 의미를 정의

분산 시스템의 속성으로 해보면

* 유일성 (펜싱 요청이 같은 값을 반환하지 않는다)
* 단조 일련번호 (시간 순서)
* 가용성 (요청하고 죽지 않은 노드는 응답한다)

모든 노드가 죽거나 모든 네트워크 지연이 길어지면?

=== 안정성 (safety) 과 활동성 (liveness)

* 안정성 - 나쁜 일은 일어나지 않는다
** 위반된 특정 시점을 가리킬 수 있다. 위반 후에는 위반을 취소할 수 없고 이미 손상된 상태
* 활동성 - 좋은 일은 결국 일어난다
** 시점을 특정하지 못할 수 있지만, 미래에 속성을 만족시킬 수 있다는 희망

=== 시스템 모델을 현실 세계에 대응시키기

실제 구현에서는 불가능하다고 가정했던 일이 발생하는 경우를 처리하는 코드를 포함시켜야 할 수 있다

이론적인 추상 시스템 모델: 관리 가능한 결함의 집합 추출, 문제를 이해하고 체계적으로 해결하려고 노력하는데 도움

이론적 분석과 경험적 실험은 똑같이 중요하다