= 12. 데이터 시스템의 미래

저자의 입장에서 미래에는 어떻게 돼야 하는지

신뢰할 수 있고, 확장 가능하며, 유지보수하기 쉽게

== 데이터 통합

특정 애플리케이션 기능을 제공하기 위해서는 여러 소프트웨어를 함께 엮어 사용해야 한다

=== 파생 데이터에 특화된 도구의 결합

전문 검색, 머신러닝, 분류, 랭킹, 추천 시스템, ... 등에 특화된 데이터 도구 사용

데이터 통합의 필요성은 조직 전체 데이터플로를 고려할 때 명확해진다

==== 데이터플로에 대한 추론

데이터 사본을 여러 저장소 시스템에 유지해야 할 때? - 입출력을 분명히 해야

==== 파생 데이터 vs 분산 트랜잭션

분산 트랜잭션은 lock 을 이용하여 쓰기 순서 결정 +
CDC 와 이벤트 소싱은 로그를 사용하여 순서 결정

분산 트랜잭션 비용을 지불할 만한 제한된 환경이면 분산 트랜잭션 사용 +
-> XA 는 결함 대응에 취약하고 성능도 나쁘다

로그 기반 파생 데이터가 이종 데이터 시스템을 통합하는 좋은 접근법이라고 생각

분산 트랜잭션과 비동기 로그 기반 시스템 사이 중간 지점을 볼 예정

==== 전체 순서화의 제약

- 순서 결정 시 단일 리더 노드가 필요
    - 처리량을 늘리기 위해 단일 -> 복수 장비로 파티션을 나누면 파티션의 이벤트 순서는 애매해진다
- 데이터센터가 나뉘면 각 데이터센터마다 독립적인 리더를 둔다
    - 전체 순서를 정하기는 어렵다
- MSA, 오프라인 클라이언트 등

단일 노드를 넘어서는 분산된 설정에서 잘 동작하는 합의 알고리즘 설계는 아직 해결되지 않음

==== 인과성 획득을 위한 이벤트 순서화

특정 객체 ID 는 특정 파티션으로 전달하면 전체 순서화가 가능하다

개별 이벤트마다 처리하는 시스템이 다르면 순서 의존성이 끊길 수 있다 (친구 끊기, 메시지 보내기 예시)

=== batch, stream 처리

spark: batch 엔진 상에서 stream 처리, flink: stream 엔진 상에서 batch 처리

==== 파생 상태 유지

batch 는 결정적이고 다른 부수 효과가 없는 순수 함수 장려, 입력 = 불변, 출력 = 추가 전용

파생 데이터 시스템을 만들 때 비동기 방식으로 하면 이벤트 로그 기반 시스템을 훨씬 견고하게 만든다 +
분산 트랜잭션은 나머지 시스템으로 실패가 확산 -> 증폭

==== 애플리케이션 발전을 위한 데이터 재처리

batch 는 누적된 과거 데이터를 재처리해 새 파생 뷰를 만들 수 있다

재처리는 시스템을 유지보수하기 좋음 - 기존 것을 건드리지 않으면서 새로운 요구사항의 데이터셋 구축

파생 뷰로 점진적 발전이 가능 - 일부 사용자에게는 새로운 뷰를 보게 하여 성능 테스트, 버그를 찾을 수 있음

==== 람다 아키텍처

batch, stream 을 조합하여 재처리

입력 데이터를 불변 이벤트로, 증가하기만 하는 데이터셋에 추가하는 방식으로 기록

단점: batch, stream 에서 같은 로직을 유지하는데 노력, 각각의 분리된 출력 병합 문제, 대용량 데이터셋에서 자주 처리하는 문제

==== batch, stream 처리의 통합

* 이벤트 스트림을 다루는 처리 엔진에서 과거 이벤트를 재생할 수 있도록
* exactly once symantic, 결함이 발생하더라도 결함이 없었던 상황과 동일한 출력을 내는 것을 보장
* 이벤트 시간 기준으로 윈도우를 처리하는 도구

== 데이터베이스 언번들링

UNIX 와 DB 의 장점을 결합하기

=== 데이터 저장소 기술 구성하기

==== 인덱스 생성하기

RDB 에서 인덱스 생성 시 - 일관된 스냅샷을 사용해 스캔 -> 필드 추출, 정렬 -> 인덱스에 기록 -> 일관된 스냅샷 이후에 생성된 backlog 처리

==== 모든 것의 meta DB

* Federated DB or Polystore: 읽기를 통합
** 하부 저장소 엔진과 처리 메소드를 통합해 질의하는 인터페이스 제공
** PostgreSQL - foreign data wrapper: 연합 인터페이스로 쉽게 처리
* Unbundling DB: 쓰기를 통합
** 여러 시스템으로 구성했을 때도 모든 데이터가 올바른 장소에 반영되도록 보장
** (CDC, 이벤트 로그를 통해) 저장소 시스템을 신뢰성 있게 결합하기 쉽게 만드는 것과 유사
** 적은 도구를 사용하는 유닉스 전통을 따름 - 저수준 API (pipe) 로 통신

==== 언번들링이 동작하게 만들기

다른 기술 사이에서 동작한다면 트랜잭션보다 비동기 이벤트 로그를 사용하는 것이 좋다 (고 생각한다)

로그 기반 통합의 장점은 느슨한 결합 - 특정 장애, 성능 저하가 전체까지 영향이 없이 만들 수 있음, 독립적인 유지보수

==== 언번들링 vs 통합 시스템

필요한 모든 것을 만족하는 단일 기술이 있다면, 사용해라. +
언번들링과 합성은 단일 기술이 없을 때 장점

그래프에 대한 재귀 질의와 애플리케이션 로직을 포함한 복잡한 질의에 대한 구체화 뷰를 선언적으로 지정하여 캐시 만들기 - differenctial dataflow

=== 데이터플로 주변 애플리케이션 설계

==== 파생 함수로서의 애플리케이션 코드

보조 색인, 전문 검색 색인, feature engineering, cache

==== 애플리케이션 코드와 상태의 분리

현대에서 대부분 DB 는 네트워크를 통해 변경 가능한 공유 변수와 같이 동작 +
DB 는 지속성있고 동시성 제어와 내결함성을 지원

대부분의 언어에서 DB 변경을 구독할 수는 없다 +
polling 이 유일한 방법

==== 데이터플로: 상태 변경과 애플리케이션 코드 간 상호작용

파생 데이터를 유지 != 전통적인 메시징 시스템의 설계 목적인 비동기 작업 실행

* 파생 데이터 유지 시 순서가 중요한 경우, 내결함성
* 최신은 지원한다

==== 스트림 처리자와 서비스

데이터플로 접근법에서는 미리 구독하고 변경이 일어날 때마다 때마다 로컬에 기록, 질의를 로컬에서

데이터플로 접근법은 훨씬 빠르고 다른 서비스 장애에도 훨씬 잘 버틸 수 있다

시간 의존성을 잘 다루어야 하는 문제는 있음

=== 파생 상태 관찰하기

그림 12-1. write/read path

==== 구체화 뷰와 캐싱

캐시, 인덱스, 구체화 뷰는 읽기 경로, 쓰기 경로 사이의 경계를 옮기는 단순한 역할 +
이런 파생 데이터셋을 사용 -> 쓰기 경로에서 더 많은 일 수행, 미리 결과를 계산할 수 있어 읽기 경로 작업이 줄어든다

==== 오프라인 대응 가능한 상태 저장 클라이언트

로컬 DB 로 많은 일을 하고, 네트워크 연결이 가능할 때 백그라운드에서 원격 서버와 동기화

==== 상태 변경을 클라이언트에게 푸시하기

개별 장치는 작은 이벤트 스트림을 구독하는 작은 구독자

==== 종단 간 이벤트 스트림

쓰기 경로를 최종 사용자까지 확장하려면 request/response -> publish/subscribe 로 변경해야 한다

==== 읽기도 이벤트다

읽기 이벤트를 기록하면, +
인과적 의존성과 시스템 전체의 데이터 출처를 추적할 수 있다 +
지속성 있는 저장소에 기록하면 추적하기가 더 용이하다

==== 다중 파티션 데이터 처리

여러 파티션의 데이터 통합이 필요한 복잡한 질의를 분산 실행할 수 있어야 하는 경우

특정 URL 을 본 사람 수, 사기 방지, ...

== 정확성을 목표로

=== 데이터베이스에 관한 종단 간 논증

DB 에서도 버그가 있을 수 있고, 애플리케이션에서 잘못된 데이터를 넣을 수도

==== 연산자의 정확히 한 번 실행

한 번 실행한 것처럼 보이게, 여러 번 실행하더라도 동일한 결과를 내는 멱등 처리

==== 연산 식별자

중복 제거보단, 연산의 고유 식별자를 만들어서 이용

==== 종단 간 논증

클라이언트 ~ DB 에 이르는 모든 경로에 트랜잭션 식별자 포함

=== 제약 조건 강제하기

==== 유일한 제약 조건은 합의가 필요

단일 리더를 두고 결정 +
유일성 검사는 유일성이 필요한 값을 기준으로 파티셔닝하여 확장

==== 로그 기반 메시징의 유일성, 다중 파티션 요청 처리

=== 적시성과 무결성

적시성 - 사용자가 항상 최신 상태로 관측 가능 (위반: 최종적 일관성) +
무결성 - 손상이 없음 (위반: 영구적 불일치)

==== 데이터플로 시스템에서 정확성

매커니즘을 결합해 달성

* 쓰기 연산 내용을 단일 메시지로 표현
* 결정적 파생 함수
* 클라이언트가 생성한 요청 ID 를 모든 단계에서 포함
* 메시지를 불변으로 만들고 필요 시 파생 데이터 재처리

=== 우선 믿고, 확인하기

버그가 발생해도 무결성 유지, 약속을 무조건 믿지 않기, 검증하는 문화 +
감사 기능 설계, 종단 간 논증, 감사 시스템용 도구 (블록체인, 분산 원장 - 머클 트리)

== 옳은 일 하기

=== 예측 분석

편견과 차별 방지, 책임과 의무, 피드백 루프 대응

=== 사생활과 추적

감시, 동의와 선택의 자유, 사생활과 데이터 사용, ...