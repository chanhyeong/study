= 6. 파티셔닝

데이터셋이 매우 크거나 처리량이 높다면 쪼개기 - 파티셔닝, 샤딩

파티셔닝하는 방법, 인덱스와 파티셔닝이 어떻게 상호작용하는지 볼 예정 +
+ 리밸런싱, DB 가 어떻게 요청을 파티션에 전달하고 쿼리하는지

== 파티셔닝과 복제

복제 + 파티셔닝 - 개별 파티션의 복사본을 여러 노드에 저장 (그림 6-1)

== key-value 데이터 파티셔닝

파티셔닝이 고르게 이루어지지 않은 상태 - **skewed** +
부하가 높은 파티션 - **hotspot**

=== key 범위 기준 파티셔닝

연속된 범위의 키를 할당 +
키 범위 크기가 반드시 동일할 필요는 없다

파티션 경계 - 관리자가 수동 선택 or DB 에서 자동으로 선택

파티션 내에서는 키를 정렬된 순서로 저장할 수 있다 +
key 를 연속적인 인덱스로 간주하여 여러 개를 읽어오는 데 사용할 수 있다

특정한 접근 패턴이 hotspot 을 유발하는 단점 - 타임스팸프가 키인 경우 등 +
(예전에 배달업체 데이터가 많아서 리밸런싱 중에 오류가 났던..)

=== key 의 해시값 기준 파티셔닝

skew, hotspot 위험으로 대부분 해시 함수 사용

언어의 해시 함수는 다른 프로세스에서는 다른 해시값을 반환할 수 있어 적합하지 않다

적합한 해시 함수 선택 -> 파티션에 해시값 범위 할당 -> 해시값이 파티션의 범위에 속하는 키들을 할당

파티션 경계는 크기가 동일하게 or 무작위에 가깝게 (consistent hashing)

.Consistent Hashing
****
캐시 시스템에서 부하를 균등하게 분산시키는 방법 +
중앙 제어나 분산 합의가 필요하지 않도록 파티션 경계를 무작위로 선택 +
일관성 = 특별한 리밸런싱 방법

DB 에서는 잘 동작하지 않아 안 쓴다

(대기열에서 이거 구현해서 쓴거로 알고 있긴 함)
****

인접했던 키들이 흩어져서 정렬 순서가 유지되지 않음 +
MongoDB 해시 기반 샤딩 -> 범위 질의가 모든 파티션에 전송 +
PK 범위 질의가 지원되지 않는 DB 들도 많음

=== 쏠린 작업부하와 핫스팟 완화

항상 동일한 키를 읽고 쓰면, 모든 요청이 하나의 파티션으로 쏠린다

간단한 해결책 - 각 키의 시작이나 끝에 임의의 숫자 붙이기 +
10진수 2개만 붙여도 100개의 다른 키로 write 가 균등하게 분산 +
100개 키에 해당하는 데이터를 읽어서 조합해야 하는 단점

== 파티셔닝과 보조 색인

여태까지의 파티셔닝은 key-value 데이터 모델

secondary index 는 특정한 조건을 검색하는 수단 +
데이터 모델링에 유용 +
문서 기반 파티셔닝 or 용어 기반 파티셔닝으로 대응

=== 문서 (Document) 기준

파티션마다 독립적인 secondary index 유지 +
CUD 작업 시 해당하는 문서 ID 를 포함하는 파티션만 다루면 된다 +
== local index

특정 조건을 검색하려면 모든 파티션으로 쿼리를 날려야 한다 (scatter/gather 방식)

(local index 가 노드별 인덱스로 알고 있었는데, 파티션별 인덱스..)

=== 용어 (Term) 기준

모든 파티션의 데이터를 담당하는 global index

용어 범위를 특정 기준으로 나누어서 인덱스를 파티션에 저장 +
(책에서는 a ~ r - 0번 파티션, s ~ z - 1번 파티션)

방식에 따라 +
용어 자체 - 범위 스캔에 유용 +
용어 해시값 - 부하 분산 +
(사내는 어떤걸 사용할지?) +
(global index 가 모든 노드에 동일한 인덱스를 유지하는건줄 알았는데, 아니었다)

local index 에 비해 읽기가 효율적이다 - scatter/gather 할 필요 없이 원하는 용어를 포함하는 파티션으로 요청 +
쓰기가 느리고 복잡하다

global index 는 대체로 비동기로 갱신

== 파티션 리밸런싱

리밸런싱 최소 요구 사항

* 리밸런싱 후에는 부하가 모든 노드에 균등하게 분배
* 리밸런싱 도중에서 DB R/W 가능
* 리밸런싱이 빨리되고, 네트워크와 디스크 I/O 부하를 최소화할 수 있도록, 필요 이상으로 옮겨지면 안된다

=== 전략

==== 쓰면 안되는 방법: 해시값에 모드 (%) N 연산을 실행

노드 개수 N 이 바뀌면 대부분의 키가 노드 사이에 옮겨져야 한다 = 필요 이상으로 이동

==== 파티션 개수 고정 (파티션 개수가 바뀌지 않음)

파티션 > 노드 대수로 설정

클러스터에 노드가 추가되면, 새 노드가 파티션이 균일하게 분배도리 때까지 기존 노드에서 파티션 몇 개를 뺏어올 수 있다 (그림 6-6)

파티션이 노드 사이에서 통째로 이동, 파티션 개수가 바뀌지 않음

파티션이 이동 중인 상태에서는 기존에 할당된 파티션 사용

초기 값을 충분히 높게 설정해야 한다 - 어떤 값을 할지 어렵긴 하다 +
너무 작으면? -> 오버헤드가 크다 +
너무 크면? -> 리밸런싱 과정과 노드 장애 복구 비용이 크다

==== 동적 파티셔닝

파티션 크기가 설정된 값을 넘어서면? -> 쪼갬 +
파티션 크기가 작아지면? -> 인접한 파티션과 합침

파티션 개수가 전체 데이터 용량에 맞춰 조정되는 이점

빈 DB 에서는 파티션 경계를 어디로 정해야할지 모른다 -> 파티션이 하나 +
문제 완화를 위해 초기 파티션 집합 설정 (사전 분할, pre-spliting) 하는 DB 들이 있다

==== 노드 비례 파티셔닝

파티션 개수가 노드 대수에 비례하게 -> 노드 당 할당되는 파티션 개수 고정

새 노드가 추가되면 고정된 개수의 파티션을 무작위로 선택 -> 분할 +
분할된 파티션 중 절반을 골라 새 노드에 할당

파티션 경계를 무작위로 선택하려면 해시 기반 파티셔닝을 사용해야 한다

=== 운영: 자동 리밸런싱, 수동 리밸런싱

완전 자동 -> 예측이 어렵다 +
요청 경로 재설정, 데이터 이동으로 인한 큰 비용 - 네트워크나 노드에 과부화, 성능 저하 +
자동 장애 감지와 조합되면 부하가 몰렸을 시 죽었다고 간주되어 리밸런싱이 일어날 수 있음 -> 상황 악화

완전 자동 보다는 개입하는게 좋을 수 있다

중간 지점: 시스템이 파티션 할당 제안 -> 관리자가 확정

== 요청 라우팅

service discovery 의 일종 - 클라이언트가 어느 노드로 접속해야 알 수 있는가

몇 가지 접근법

. 클라이언트가 아무 노드 접속 -> 적합한 파티션이 있으면 처리, 없으면 올바른 노드로 전달하여 응답 전달
** gossip protocol
. 클라이언트의 모든 요청을 라우팅 계층으로 보냄 -> 라우팅 계층에서 처리할 노드를 알아내고 전달 (partition-aware loadbalancer)
** Helix, mongos, moxi
. 클라이언트가 파티셔닝 방법과 파티션이 어떤 노드에 할당됐는지 알고 있게

Zookeeper 에서 파티션과 노드 사이의 할당 정보 관리 -> 변경되면 라우팅 계층에 알려서 최신으로 유지

=== 병렬 질의 실행

분석용 대규모 병렬 처리 (massively parallel processing, MPP) +
join, filtering, grouping, aggregation

서로 다른 노드에서 병렬적으로 실행될 수 있다