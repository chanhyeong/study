= 11. 스트림 처리

stream: 시간 흐름에 따라 점진적으로 생산된 데이터

스트림 표현, 저장, 네트워크 상에서 전송하는 방법 +
스트림과 DB 사이의 관계, 연속적으로 스트림을 처리하는 접근법과 도구

== 이벤트 스트림 전송

이벤트: 특정 시점에 일어난 사건에 대한 세부 사항을 포함하는 작고 독립된 불변 객체 +
일기준 시계를 따르는 이벤트 발생 타임스탬프 포함

텍스트 문자열 or JSON or binary format 으로 인코딩된다

producer (publisher, sender) 가 이벤트를 한 번 만들면 +
복수의 consumer (subscriber, recipient) 가 처리할 수 있다

관련 이벤트는 topic or stream 으로 묶는다

방법으로 DB trigger 가 있긴 하지만 적합하지 않다

=== 메시징 시스템

. 메시지 생산 속도 > 메시지 처리 속도 ?
** 버리거나, 버퍼링하거나, 배압 (backpressure, 흐름제어 (flow-controler). 더 못보내게 막음)
** 버퍼링 시 큐 증가에 따라 어떤 현상이 생기는지 이해가 중요 - 시스템 중단? 디스크에 쓰기? 디스크 접근이 시스템의 성능에 어떤 영향을 주는지
. 노드가 죽거나 일시 중단된 경우 ?
** 디스크에 기록 or 복제본 생성 or 둘 다

==== 생산자에서 소비자로 메시지를 직접 전달하기

중간 노드를 통하지 않고 생산자와 소비자를 네트워크로 직접 통신

소비자가 오프라인이면 전송된 메시지가 유실될 수 있다

==== 메시지 브로커

메시지 스트림을 처리하는 데 최적화된 DB 의 일종 +
생산자: 브로커로 메시지 전송, 소비자: 브로커에서 메시지를 읽음

==== 메시지 브로커 vs DB

[cols="1,1"]
|===
|broker |DB

|소비자에게 전송이 성공할 경우 삭제 |보관

|큐 크기가 작음, 버퍼링할 경우 개별 처리 시간이 길어지고 전체 처리량 감소 |-

|특정 패턴과 부합하는 토픽의 부분집합 구독 지원 |보조 색인 지원 (필요한 데이터 부분을 선택하는 방법)

|데이터가 변하면 알려줌 |데이터가 변해도 스냅샷 기준으로 해서 클라이언트가 모름

|===

==== 복수 소비자

로드 밸런싱 (개 중 하나에만 전송), 팬 아웃 (모든 소비자에게 전송)

==== 확인 응답과 재전송

클라이언트는 메시지 처리가 끝났을 때 브로커에게 명시적으로 알려야 한다

=== 파티셔닝된 로그

DB 의 지속성 있는 저장 방법 + 메시징 시스템의 지연 시간이 짧은 알림 기능 조합 -> log-based message broker

==== 로그를 사용한 메시지 저장소

생산자가 보낸 메시지를 로그 끝에 추가, 소비자는 로그를 순차적으로 읽어 메시지를 받음

파티셔닝으로 처리량을 높일 수 있음 - 다른 파티션은 다른 장비에서 서비스

모든 메시지를 디스크에 저장, 여러 장비에 파티셔닝하여 처리량이 좋고, 복제함으로 장애에 대비

==== 로그 방식 vs 전통적인 메시징 방식

* 처리량이 토픽의 파티션 수로 제한
* 특정 메시지가 느리면 후속 메시지 처리가 지연된다

==== 소비자 오프셋

어디까지 처리했는지 알기 위해 소비자의 오프셋 기록

==== 디스크 공간 사용

로그는 크기가 제한된 버퍼로 구현, 버퍼가 가득차면 오래된 순서대로 버림 - circular/ring buffer

==== 소비자가 생산자를 따라갈 수 없을 때

특정 소비자가 뒤쳐지면 해당 소비자만 영향을 받고, 나머지를 망치지 않음 +
소비자가 종료되거나 죽으면 자원 소비 중단, 소비자 오프셋만 남는다

전통적 메시지 브로커에서는 소비자가 사용하던 큐를 삭제 - 불필요한 메시지 누적 방지

==== 오래된 메시지 재생

오프셋을 이동시켜 재처리

== 데이터베이스와 스트림

=== 시스템 동기화 유지하기

DB 덤프, dual write, ...

=== CDC

change data capture - DB 에 기록하는 모든 데이터의 변화 관찰, 다른 시스템으로 복제할 수 있는 형태로 추출

==== CDC 의 구현

변경 사항을 캡처할 DB 하나를 리더, 나머지를 팔로워 +
로그 기반 메시지 브로커는 원본 DB 에서 변경 이벤트를 전송하기 적합 - 메시지 순서를 유지하기 때문

CDC 는 비동기 방식으로 동작, 변경 사항을 커밋하기 전에 소비자에게 적용될 때까지 기다리지 않음

==== 초기 스냅샷

생략

==== 로그 컴팩션

같은 키의 로그 레코드에 대해 가장 최근에 갱신된 값만 유지

==== 변경 스트림용 API 지원

DB 단에서 지원

=== 이벤트 소싱

애플리케이션 상태 변화를 모두 변경 이벤트 로그로 저장

사용자의 행동을 불변 이벤트로 기록, 애플리케이션을 지속해서 개선하기 유리, 디버깅 도움, 버그 방지

==== 이벤트 로그에서 현재 상태 파생하기

마지막 상태를 재구축하기 위해서는 이벤트의 전체 히스토리가 필요 - 로그 컴팩션 불가능

==== 명령과 이벤트

명령은 실패할 수 있다, 조건이 검증되고 승인되면 지속성 있는 불변 이벤트가 된다

이벤트는 생성 시점에 사실(fact)이 된다

이벤트 스트림 소비자는 이벤트를 거절하지 못한다 +
그래서 명령의 유효성은 이벤트가 되기 전에 동기식으로 검증해야 한다

예약 요청을 두 개로 분할할 수도 - 가예약 이벤트, 유효한 예약에 대한 확정 이벤트

=== 상태와 스트림 그리고 불변성

상태가 어떻게 바뀌든 변화를 일으킨 이벤트가 있다 +
changelog 는 시간이 지남에 따라 바뀌는 상태

애플리케이션의 상태를 시간에 따른 이벤트 스트림을 적분해서 구할 수 있고, 변경 스트림은 시간으로 상태를 미분해서 구할 수 있다

로그를 지속성 있게 저장한다면 상태를 재생성할 수 있음

(사실 상태를 시간으로 미분하는건 거의 불가능하지 않은지..)

==== 불변 이벤트의 장점

거래가 발생하면 정보를 원장에 추가만 하는 방식으로 기록 +
실수가 발생하면 실수를 보완하는 거래 내역 추가

불변 이벤트는 현재 상태보다 많은 정보를 포함

==== 동일한 이벤트 로그로 여러가지 뷰 만들기

이벤트 로그 -> DB 변환하는 명시적 단계가 있으면, 애플리케이션 발전이 쉬움 +
기존 데이터를 새로운 방식으로 표현 - 이벤트 로그로 신규 기능용으로 분리한 일기 최적화된 뷰 구축 가능

데이터를 쓰는 형식과 읽는 형식을 분리하여 다양한 읽기 뷰를 허용 -> 유연성을 얻을 수 있다. CQRS

읽기 최적화된 뷰는 데이터를 비정규화하는 것이 합리적, 변환 프로세스가 뷰와 이벤트 로그 사이의 일관성을 유지하는 메커니즘을 제공하기 때문

==== 동시성 제어

비동기이기 때문에 사용자가 기록 후 읽을 때 아직 반영이 안되어 있을 수 있음

해결책 - 읽기 뷰의 갱신과 로그에 이벤트를 추가하는 작업을 동기식으로 수행 +
-> 이벤트 로그와 읽기 뷰를 같은 저장 시스템에 담아야 한다

==== 불변성의 한계

적은 데이터셋에서 빈번한 갱신/삭제를 하는 작업부하는 불변 히스토리가 감당하기 어렵거나, 파편화 문제가 발생할 수도 +
compaction 과 gc 성능 문제도 골칫거리

히스토리를 새로 쓰고, 문제가 되는 데이터를 처음부터 기록하지 않았던 것처럼 - exicision/shunning

== 스트림 처리

스트림을 처리해 다른 파생 스트림을 생산. 스트림을 처리하는 코드 조각을 연산자 (operator) or 작업 (job)

실행 중인 스트림 작업은 처음부터 재시작은 비현실적

=== 스트림 처리의 사용

==== 복잡한 이벤트 처리 (complex event processing)

query 를 처리 엔진에 제출, 처리 엔진이 입력 스트림을 소비해 필요한 매칭을 수행하는 상태 기계 유지 +
해당 매치 발견 시 complex event 방출

==== 스트림 분석

대량의 이벤트를 집계하고 통계적 지표를 뽑기 +
일반적으로 고정된 시간 간격 기준

==== 기타

구체화 뷰 유지하기, 스트림 상에서 검색하기, 메시지 전달과 RPC

=== 시간에 관한 추론

스트림 처리 프레임워크는 윈도우 시간을 정할 때 장비의 시스템 시계 (처리 시간) 을 이용

==== 이벤트 시간 vs 처리 시간

이벤트 시간과 처리 시간의 불연속을 대처할 알고리즘을 명확히 작성할 필요가 있다

==== 준비 여부 인식

(네트워크 지연 등으로) 윈도우를 종료한 이후에 도착한 낙오자 이벤트 처리 방법 +
-> 버린다 = 낙오자는 대체로 적은 비율 +
-> 수정 값을 발행 = 낙오자 이벤트가 포함된 윈도우를 기준으로 갱신된 값

==== 어떤 시계를 사용할 것인가?

. 이벤트가 발생한 시간. 장치 시계
. 이벤트를 서버로 보낸 시간. 장치 시계
. 서버에서 이벤트를 받은 시간. 서버 시계

2, 3 의 차이를 구하면 장치 시계와 서버 시계 간의 오프셋을 추정할 수 있음 -> 오프셋을 이벹트 타임스탬프에 적용해 발생한 시간을 추정할 수 있음

==== 윈도우 유형

* Tumbling = 고정 크기, 이벤트는 정확히 한 윈도우에 속함
* Hopping = 고정 크기, 윈도우가 중첩될 수 있음
* Sliding = 고정된 경계
* Session = 같은 사용자가 발생시킨 모든 윈두오를 그룹화해서 정의

=== 스트림 조인

stream-stream, stream-table, table-table

==== stream-stream (window)

스트림 처리자가 상태를 유지 +
지난 시간에 발생한 모든 이벤트를 세션 ID 로 색인 -> 검색, 클릭 이벤트가 발생할 때마다 색인에 추가, 다른 이벤트가 올 때마다 확인 +
이벤트가 매칭되면 관련 이벤트 방출, 이벤트가 매칭 없이 만료되면 관련 이벤트 방출

==== stream-table (stream enriching)

DB 에서 정보를 찾아 추가 +
DB 원격 질의 or DB 사본을 스트림 처리자 내부에 적재 (CDC 등으로 최신 상태 유지)

==== table-table (구체화 뷰 유지)

두 테이블을 조인하는 질의에 대한 구체화 뷰를 유지 +
대상 테이블이 변할 때마다 갱신

==== 조인의 시간 의존성

스트림 처리자가 하나의 조인 입력을 기반으로 한 특정 상태르르 유지해야 하고, +
다른 조인 입력에서 온 메시지에 그 상태를 질의

비슷한 시각에 다른 스트림에서 발생한 이벤트가 있으면 어떻게 - 천천히 변하는 차원 (slowly changing dimension, SCD) 문제 +
조인되는 레코드의 특정 버전을 가리키는 데 유일한 식별자를 사용해 해결 +
조건이 바뀔 때마다 새 식별자 부여 - 이벤트 시점의 조건 식별자를 포함

=== 내결함성

exactly-once (effectively-once)

==== 마이크로 일괄 처리 (microbatching) 와 체크포인트

* microbatching: 스트림을 작은 블록으로 나누고, 각 블록을 소형 일괄 처리와 같이 다루기
** 처리 크기를 약 1초로 타협
* checkpoint: 상태의 롤링 체크포인트를 생성하여 지속성 있는 저장소에 저장 - 장애 발생 시 가장 최근 체크포인트에서 재시작, 해당 체크포인트와 장애 발생 사이의 출력을 버림

==== 원자적 커밋 재검토

장애 발생 시 성공 시에만 모든 출력과 이벤트 처리의 부수 효과가 발생하게 해야 한다

==== 멱등성

여러 번 수행하더라도 한 번만 수행한 것과 같은 효과

==== 실패 후 상태 재구축하기

상태가 필요한 스트림 처리는 실패 후에도 해당 상태가 복구됨을 보장해야 한다

개별 메시지를 원격 데이터 저장소에 상태를 유지하고 복제 +
스트림 처리자의 로컬에 상태를 유지, 주기적으로 복제